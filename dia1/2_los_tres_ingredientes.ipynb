{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc7YYAWUiM7x"
   },
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dcfp7XjiiFlq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import load_iris\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2WrGjkxjEnI"
   },
   "source": [
    "# Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmHq3ZTjjNQo"
   },
   "outputs": [],
   "source": [
    "# En PyTorch, los datasets deben heredar de torch.utils.data.Dataset\n",
    "class IrisDataset(Dataset):\n",
    "    # Inicializamos el dataset cargando los datos\n",
    "    def __init__(self):\n",
    "        data = load_iris()\n",
    "        self.X = torch.tensor(\n",
    "            data.data, dtype=torch.float32\n",
    "        )  # (150, 4)\n",
    "        self.y = torch.tensor(\n",
    "            data.target, dtype=torch.long\n",
    "        )  # (150,)\n",
    "\n",
    "    # PyTorch necesita saber el tamaño del dataset\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    # PyTorch necesita poder indexar el dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJScQRhnjWld"
   },
   "outputs": [],
   "source": [
    "full_iris_dataset = IrisDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplos de muestras\n",
    "for i in [1, 50, 100]:\n",
    "    x, y = full_iris_dataset[i]\n",
    "    print(f\"Muestra {i}: x = {x}, y = {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_iris_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NISQ1Mlsi0ap"
   },
   "source": [
    "# Definición de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnlZ3x4yi7Hd"
   },
   "outputs": [],
   "source": [
    "class IrisRed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.fc1(x)   # (B, 3)\n",
    "        return h\n",
    "    \n",
    "# el softmax no se suele incluir en el modelo porque\n",
    "# 1) la función de pérdida CrossEntropyLoss ya lo incluye\n",
    "# 2) y porque en inferencia se suele usar argmax (selección de la clase con mayor puntuación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafo computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo y el loss\n",
    "# En PyTorch, el loss y el modelo suelen ser instanciados por separado\n",
    "model = IrisRed()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Input dummy (batch size = 5)\n",
    "x = torch.randn(5, 4, requires_grad=False)\n",
    "\n",
    "# Forward\n",
    "y = model(x)\n",
    "# Loss\n",
    "target = torch.tensor([1, 0, 2, 1, 2])  # clase verdadera\n",
    "loss = criterion(y, target)\n",
    "\n",
    "\n",
    "# Crear grafo computacional\n",
    "dot = make_dot(loss, params=dict(model.named_parameters()))\n",
    "\n",
    "# Mostrar o guardar\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent, dividr en batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pu7Va7ztkXlq"
   },
   "outputs": [],
   "source": [
    "# esta función devuelve un iterador sobre batches\n",
    "dataloader = DataLoader(full_iris_dataset, batch_size=16, shuffle=True)\n",
    "# por otro lado, la red se ha definido para procesar batches de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4RZuVPJkp3M"
   },
   "source": [
    "# Juntamos los tres ingredientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2PrRNNpk3-G"
   },
   "outputs": [],
   "source": [
    "# instanciar modelo, loss y optimizador\n",
    "# si se dispone de GPU, mover el modelo a GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# la red se inicializa a pesos aleatorios cada vez que se instancia\n",
    "model = IrisRed().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4lT1ejkksNd"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "# durante un número de epochs\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # poner el modelo en modo entrenamiento\n",
    "    model.train()\n",
    "    # para llevar la cuenta del loss\n",
    "    running_loss = 0.0\n",
    "    n_seen = 0\n",
    "    for xB, yB in dataloader:\n",
    "        xB, yB = xB.to(device), yB.to(device)\n",
    "        optimizer.zero_grad()      # reset gradientes\n",
    "        logits = model(xB)         # forward\n",
    "        loss = criterion(logits, yB)\n",
    "        loss.backward()            # backward\n",
    "        optimizer.step()           # update\n",
    "        running_loss += loss.item() * xB.size(0) # para llevar la cuenta del loss\n",
    "        n_seen += xB.size(0)           # para llevar la cuenta del loss\n",
    "    epoch_loss = running_loss / n_seen # loss medio en la epoch\n",
    "    print(f\"Epoch {epoch:03d} | train_loss = {epoch_loss:.4f}\") # reportamos el loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjFigsuqlk-a"
   },
   "source": [
    "# Ejercicio\n",
    "\n",
    "Divide el dataset en train y test, y entrena el modelo durante 100 epochs. Evalúa el accuracy en el conjunto de test.\n",
    "- `torch.utils.data.random_split`\n",
    "- `torch.argmax`\n",
    "\n",
    "Recuerda poner el modelo en modo evaluación con `model.eval()` cuando evalúes en el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitectura Transformer\n",
        "Este notebook está diseñado para acompañar la sección **Arquitectura Transformer** de las diapositivas.\n",
        "\n",
        "Incluye:\n",
        "- Repaso rápido de PLN (tareas típicas)\n",
        "- Atención (Q,K,V) con intuición + matemática\n",
        "- Self-attention, máscara causal, multi-head attention\n",
        "- Residual + LayerNorm (Pre-Norm) + FFN\n",
        "- Encoder, Decoder, y Transformer Encoder–Decoder **desde cero** (mini-implementación sencilla)\n",
        "- Ejercicios (TODO) intercalados\n"
      ],
      "metadata": {
        "id": "PdIn_TLgCAMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FQl_v8ZM5Zn9",
        "outputId": "ac30c91e-0cc1-4985-ba2a-6431d7ec4057"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed = 42\n",
        "set_seed(seed)\n",
        "print('Seed set with value ', seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc2FclQhCMkr",
        "outputId": "64ddca46-0a89-4aa2-ec65-908926dad6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set with value  42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Mini repaso PLN (muy breve)\n",
        "Tareas comunes:\n",
        "- Tokenización / subwords\n",
        "- POS / NER\n",
        "- Clasificación (sentimiento, spam)\n",
        "- Traducción / resumen\n",
        "- QA\n",
        "\n",
        "Problema central: **texto → números** (IDs → embeddings).\n",
        "\n",
        "## 2) Atención: intuición y fórmula\n",
        "### Intuición (Q, K, V)\n",
        "- **Query (Q)**: lo que *busco*.\n",
        "- **Key (K)**: cómo describo cada elemento *disponible*.\n",
        "- **Value (V)**: la información que *me llevo* si atiendo a ese elemento.\n",
        "\n",
        "La atención hace:\n",
        "1) calcula similitud entre Q y K (scores)\n",
        "2) normaliza con softmax → pesos\n",
        "3) combina V con esos pesos → salida\n",
        "\n",
        "### Fórmula\n",
        "$$\\mathrm{Att}(Q,K,V)=\\mathrm{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V$$\n"
      ],
      "metadata": {
        "id": "WNe9QUjECU-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación base: scaled dot-product attention"
      ],
      "metadata": {
        "id": "uf7xmz1ICaq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(Q, K, V, mask=None, dropout_p=0.0):\n",
        "    \"\"\"\n",
        "    Scaled dot-product attention (núcleo del Transformer).\n",
        "\n",
        "    Q: (B, h, Tq, d)  queries\n",
        "    K: (B, h, Tk, d)  keys\n",
        "    V: (B, h, Tk, d)  values\n",
        "    mask: (1 o B, 1 o h, Tq, Tk)\n",
        "          0    -> permitido\n",
        "          -inf -> bloqueado\n",
        "    \"\"\"\n",
        "    # Dimensión por head\n",
        "    d = Q.size(-1)\n",
        "\n",
        "    # Producto punto QK^T escalado\n",
        "    # Resultado: (B, h, Tq, Tk)\n",
        "    scores = (Q @ K.transpose(-2, -1)) / math.sqrt(d)\n",
        "\n",
        "    # Aplicamos máscara si existe (padding o causal)\n",
        "    if mask is not None:\n",
        "        scores = scores + mask\n",
        "\n",
        "    # Softmax sobre las keys (última dimensión)\n",
        "    attn = F.softmax(scores.float(), dim=-1).type_as(scores)\n",
        "\n",
        "    # Dropout opcional sobre la atención\n",
        "    if dropout_p > 0:\n",
        "        attn = F.dropout(attn, p=dropout_p, training=True)\n",
        "\n",
        "    # Combinación ponderada de los values\n",
        "    # Resultado: (B, h, Tq, d)\n",
        "    out = attn @ V\n",
        "\n",
        "    return out, attn\n",
        "\n",
        "# Test rápido de shapes\n",
        "B,h,T,d = 2, 4, 5, 8\n",
        "Q = torch.randn(B,h,T,d)\n",
        "K = torch.randn(B,h,T,d)\n",
        "V = torch.randn(B,h,T,d)\n",
        "out, attn = scaled_dot_product_attention(Q,K,V)\n",
        "print('out:', out.shape)\n",
        "print('attn:', attn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwlHl-qJCW5D",
        "outputId": "6134a9fd-bcea-4860-be85-b52b999809b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out: torch.Size([2, 4, 5, 8])\n",
            "attn: torch.Size([2, 4, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1 (shapes y softmax)\n",
        "**TODO:**\n",
        "1) Comprueba que `attn.sum(dim=-1)` vale 1 (aprox) en cada query.\n",
        "2) Explica por qué el softmax se aplica en la dimensión de `Tk` (tokens a los que atiendes).\n"
      ],
      "metadata": {
        "id": "wYRniC3WDJI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Máscara causal (masked self-attention)\n",
        "En modelos autoregresivos (tipo GPT), el token en posición *t* **no puede ver el futuro**.\n",
        "\n",
        "Creamos una máscara triangular superior con `-inf` para bloquear."
      ],
      "metadata": {
        "id": "xPrFA19wDMeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_mask(T, device=None):\n",
        "    # (1,1,T,T)\n",
        "    m = torch.full((1,1,T,T), float('-inf'), device=device)\n",
        "    m = torch.triu(m, diagonal=1)\n",
        "    return m\n",
        "\n",
        "T=6\n",
        "m = causal_mask(T)\n",
        "print(m[0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1B_VTS1DO30",
        "outputId": "8585ac78-9685-40ff-87e3-be51da0f8867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo: la máscara hace que la atención al futuro sea 0 tras softmax"
      ],
      "metadata": {
        "id": "NzIeV2e2Dj9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B,h,T,d = 1,1,5,4\n",
        "Q = torch.randn(B,h,T,d)\n",
        "K = torch.randn(B,h,T,d)\n",
        "V = torch.randn(B,h,T,d)\n",
        "mask = causal_mask(T)\n",
        "_, attn_masked = scaled_dot_product_attention(Q,K,V,mask=mask)\n",
        "print('attn (masked) matrix:')\n",
        "print(attn_masked[0,0].detach())\n",
        "print('Suma por fila:', attn_masked[0,0].sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhvN7MS4DjAU",
        "outputId": "900d3383-63aa-4326-d191-6852e94726bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attn (masked) matrix:\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4520, 0.5480, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3310, 0.1989, 0.4701, 0.0000, 0.0000],\n",
            "        [0.3105, 0.1214, 0.5049, 0.0632, 0.0000],\n",
            "        [0.1016, 0.1071, 0.0999, 0.4880, 0.2034]])\n",
            "Suma por fila: tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2 (interpretación de máscara)\n",
        "**TODO:**\n",
        "1) ¿Qué posiciones exactas se bloquean cuando `diagonal=1`?\n",
        "2) ¿Por qué dejamos la diagonal en 0 (permitida)?\n"
      ],
      "metadata": {
        "id": "hDY7em4mDm2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "se bloquean exactamente todas las posiciones por encima de la diagonal principal.\n",
        "\n",
        "Formalmente, para una matriz (T, T):\n",
        "\n",
        "*   Se bloquean las posiciones (i, j) tales que\n",
        "j > i\n",
        "*   Se permiten las posiciones (i, j) tales que\n",
        "j ≤ i\n",
        "\n"
      ],
      "metadata": {
        "id": "ooy7SagyD6H5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La diagonal corresponde a i == j, es decir: **el token se atiende a sí mismo**\n",
        "\n",
        "¿Por qué esto es necesario?\n",
        "\n",
        "1. Identidad / copia\n",
        "* El token actual debe poder usar su propia representación.\n",
        "* Si bloqueas la diagonal, el token no puede verse a sí mismo → pierdes información.\n",
        "\n",
        "2. Estabilidad del modelo\n",
        "\n",
        "* En la práctica, mucha información útil viene de la propia posición.\n",
        "\n",
        "* Bloquear la diagonal hace el entrenamiento inestable y peor.\n",
        "\n",
        "3. Interpretación correcta del LM\n",
        "* En un modelo autoregresivo, queremos: \"puedes usar el pasado y el presente, pero no el futuro\"\n"
      ],
      "metadata": {
        "id": "27C8OjXlEIpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Multi-Head Attention (MHA)\n",
        "En vez de una sola atención, usamos **h cabezas**. Cada cabeza trabaja en un subespacio de dimensión `head_dim = d_model / h`.\n",
        "\n",
        "Pasos:\n",
        "1) Proyectar: Q=XWq, K=XWk, V=XWv\n",
        "2) Separar en cabezas (reshape)\n",
        "3) Atención por cabeza\n",
        "4) Concatenar cabezas\n",
        "5) Proyección final Wo\n"
      ],
      "metadata": {
        "id": "NUcmL7ryEjyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementación de Multi-Head Attention (self- o cross-attention).\n",
        "\n",
        "    - d_model: dimensión total del modelo\n",
        "    - n_heads: número de cabezas de atención\n",
        "    - is_causal: si True, usa máscara causal (autoregresiva)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, dropout=0.0, is_causal=False, max_seq_len=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        # d_model debe poder dividirse entre el número de heads\n",
        "        assert d_model % n_heads == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads  # dimensión por cabeza\n",
        "        self.is_causal = is_causal\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Proyecciones lineales para Queries, Keys y Values\n",
        "        # Cada una proyecta d_model -> d_model\n",
        "        self.wq = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.wk = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.wv = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        # Proyección final para recombinar las heads\n",
        "        self.wo = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        # Si es atención causal, precomputamos la máscara triangular superior\n",
        "        # Shape: (1, 1, max_seq_len, max_seq_len)\n",
        "        if is_causal:\n",
        "            m = torch.full((1, 1, max_seq_len, max_seq_len), float('-inf'))\n",
        "            m = torch.triu(m, diagonal=1)\n",
        "            # register_buffer => se mueve con .to(device), pero no es un parámetro entrenable\n",
        "            self.register_buffer('mask', m)\n",
        "        else:\n",
        "            self.mask = None\n",
        "\n",
        "    def forward(self, x, kv=None):\n",
        "        \"\"\"\n",
        "        x:  (B, T, d_model)\n",
        "        kv: (B, Tk, d_model) o None\n",
        "\n",
        "        - Si kv=None: self-attention (Q,K,V vienen de x)\n",
        "        - Si kv!=None: cross-attention (Q de x, K/V de kv)\n",
        "        \"\"\"\n",
        "        B, T, _ = x.shape\n",
        "\n",
        "        # Self-attention si no se proporciona kv\n",
        "        if kv is None:\n",
        "            kv = x\n",
        "\n",
        "        B2, Tk, _ = kv.shape\n",
        "        assert B2 == B  # batch debe coincidir\n",
        "\n",
        "        # Proyecciones lineales\n",
        "        # q: (B,T,d)   k,v: (B,Tk,d)\n",
        "        q = self.wq(x)\n",
        "        k = self.wk(kv)\n",
        "        v = self.wv(kv)\n",
        "\n",
        "        # Reorganizamos para multi-head:\n",
        "        # (B,T,d) -> (B,h,T,head_dim)\n",
        "        q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, Tk, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, Tk, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Seleccionamos la porción necesaria de la máscara causal\n",
        "        mask = None\n",
        "        if self.is_causal:\n",
        "            # (1,1,T,Tk) – se broadcasta a (B,h,T,Tk)\n",
        "            mask = self.mask[:, :, :T, :Tk]\n",
        "\n",
        "        # Atención escalada\n",
        "        # out:  (B,h,T,head_dim)\n",
        "        # attn: (B,h,T,Tk)\n",
        "        out, attn = scaled_dot_product_attention(\n",
        "            q, k, v,\n",
        "            mask=mask,\n",
        "            dropout_p=self.dropout\n",
        "        )\n",
        "\n",
        "        # Recombinar las heads:\n",
        "        # (B,h,T,head_dim) -> (B,T,d_model)\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, self.d_model)\n",
        "\n",
        "        # Proyección final\n",
        "        out = self.wo(out)\n",
        "\n",
        "        return out, attn\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Test de shapes\n",
        "# -------------------------\n",
        "mha = MultiHeadAttention(\n",
        "    d_model=32,\n",
        "    n_heads=4,\n",
        "    is_causal=True,\n",
        "    max_seq_len=64\n",
        ")\n",
        "\n",
        "x = torch.randn(2, 10, 32)\n",
        "\n",
        "y, attn = mha(x)\n",
        "\n",
        "print('y:', y.shape)       # (B,T,d_model) = (2,10,32)\n",
        "print('attn:', attn.shape) # (B,h,T,T) = (2,4,10,10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4ykn6WJEhfp",
        "outputId": "1e320a3a-bdf1-4e87-b3d0-a950abeb3e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: torch.Size([2, 10, 32])\n",
            "attn: torch.Size([2, 4, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Bloques del Transformer: FFN, LayerNorm, Residual (Pre-Norm)\n",
        "Un bloque típico (Pre-Norm) hace:\n",
        "- `x = x + Attention(LN(x))`\n",
        "- `x = x + FFN(LN(x))`\n",
        "\n",
        "El FFN es *position-wise*: la misma MLP se aplica a cada posición."
      ],
      "metadata": {
        "id": "n0dOhcsQFbjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Feed-Forward Network del Transformer.\n",
        "    Se aplica de forma independiente en cada posición.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, hidden_dim, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Proyección d_model -> hidden_dim\n",
        "        self.w1 = nn.Linear(d_model, hidden_dim)\n",
        "\n",
        "        # Proyección hidden_dim -> d_model\n",
        "        self.w2 = nn.Linear(hidden_dim, d_model)\n",
        "\n",
        "        # Dropout para regularización\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, T, d_model)\n",
        "        \"\"\"\n",
        "        return self.drop(\n",
        "            self.w2(\n",
        "                F.relu(self.w1(x))\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Capa Encoder Transformer (Pre-LayerNorm).\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, ffn_hidden, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Normalización antes de la atención\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Multi-Head Self-Attention\n",
        "        self.attn = MultiHeadAttention(\n",
        "            d_model=d_model,\n",
        "            n_heads=n_heads,\n",
        "            dropout=dropout,\n",
        "            is_causal=False\n",
        "        )\n",
        "\n",
        "        # Normalización antes de la FFN\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Feed-Forward Network\n",
        "        self.ffn = FeedForward(d_model, ffn_hidden, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, T, d_model)\n",
        "        devuelve: (B, T, d_model)\n",
        "        \"\"\"\n",
        "\n",
        "        # ---- Bloque de self-attention ----\n",
        "        # Normalizamos primero (Pre-LN)\n",
        "        h, _ = self.attn(self.ln1(x))\n",
        "\n",
        "        # Residual connection\n",
        "        x = x + h\n",
        "\n",
        "        # ---- Bloque Feed-Forward ----\n",
        "        # Normalizamos antes de la FFN\n",
        "        x = x + self.ffn(self.ln2(x))\n",
        "\n",
        "        return x\n",
        "layer = TransformerEncoderLayer(d_model=32, n_heads=4, ffn_hidden=64, dropout=0.1)\n",
        "x = torch.randn(2, 7, 32)\n",
        "y = layer(x)\n",
        "print('y:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_XHGuCUFX9Z",
        "outputId": "d61e083e-9133-4947-f160-9d32192ace93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: torch.Size([2, 7, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Positional Encoding (sinusoidal)\n",
        "La atención no sabe orden por sí sola. Sumamos una codificación posicional.\n",
        "Implementamos la sinusoidal del paper clásico."
      ],
      "metadata": {
        "id": "AFOm7pAIEzNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding sinusoidal (Vaswani et al., 2017).\n",
        "\n",
        "    Añade información de posición a los embeddings de entrada.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_len, d_model):\n",
        "        super().__init__()\n",
        "\n",
        "        # Tabla de codificaciones posicionales\n",
        "        # Shape: (max_len, d_model)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Posiciones: (max_len, 1)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        # Términos de escala para las frecuencias\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        # Dimensiones pares → seno\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Dimensiones impares → coseno\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Guardamos como buffer (no entrenable)\n",
        "        # Shape final: (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, T, d_model)\n",
        "        devuelve: (B, T, d_model)\n",
        "        \"\"\"\n",
        "        # Sumamos la codificación posicional hasta la longitud T\n",
        "        return x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
        "\n",
        "pe = PositionalEncoding(max_len=50, d_model=32)\n",
        "x = torch.zeros(1, 10, 32)\n",
        "y = pe(x)\n",
        "print('PE added shape:', y.shape)\n",
        "print('Primer vector pos0 (primeras 6 dims):', y[0,0,:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ4ce3WNEm57",
        "outputId": "e00eb3c6-0215-4d3d-eca6-e72b3a02ecd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PE added shape: torch.Size([1, 10, 32])\n",
            "Primer vector pos0 (primeras 6 dims): tensor([0., 1., 0., 1., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Encoder (stack de capas)\n",
        "El encoder aplica N veces el bloque self-attention + ffn.\n",
        "Salida: representaciones contextualizadas para cada token."
      ],
      "metadata": {
        "id": "VBp1RsZME96f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder Transformer: pila de capas TransformerEncoderLayer.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_layers, d_model, n_heads, ffn_hidden, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Creamos una lista de capas encoder idénticas en estructura\n",
        "        # (pero con parámetros independientes)\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(\n",
        "                d_model=d_model,\n",
        "                n_heads=n_heads,\n",
        "                ffn_hidden=ffn_hidden,\n",
        "                dropout=dropout\n",
        "            )\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        # Normalización final\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (B, T, d_model)\n",
        "        devuelve: (B, T, d_model)\n",
        "        \"\"\"\n",
        "        # Pasamos la entrada por cada capa del encoder\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Normalización final\n",
        "        return self.ln(x)\n",
        "\n",
        "enc = Encoder(n_layers=2, d_model=32, n_heads=4, ffn_hidden=64, dropout=0.1)\n",
        "x = torch.randn(2, 8, 32)\n",
        "h = enc(x)\n",
        "print('enc out:', h.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TkvFVRdE_ok",
        "outputId": "bd7f209a-5a67-4d92-987b-fc91c08c0b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc out: torch.Size([2, 8, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Decoder layer (masked self-attn + cross-attn + ffn)\n",
        "El decoder en un Transformer de traducción tiene 3 subcapas:\n",
        "1) Masked self-attention (causal)\n",
        "2) Cross-attention (Q del decoder, K/V del encoder)\n",
        "3) FFN\n"
      ],
      "metadata": {
        "id": "SDHjDIfJFm_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Capa Decoder Transformer (estilo Pre-LayerNorm) con:\n",
        "      1) masked self-attention (causal)\n",
        "      2) cross-attention (atiende a la salida del encoder)\n",
        "      3) feed-forward network (FFN)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, n_heads, ffn_hidden, dropout=0.0, max_seq_len=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        # ---- Bloque 1: masked self-attention ----\n",
        "        # LN antes del sub-bloque (Pre-LN)\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        # Self-attention causal: cada posición t solo puede mirar a <= t\n",
        "        self.self_attn = MultiHeadAttention(\n",
        "            d_model, n_heads, dropout=dropout, is_causal=True, max_seq_len=max_seq_len\n",
        "        )\n",
        "\n",
        "        # ---- Bloque 2: cross-attention ----\n",
        "        # LN antes del sub-bloque (Pre-LN)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        # Cross-attention NO causal: Q viene del decoder, K/V vienen del encoder\n",
        "        self.cross_attn = MultiHeadAttention(\n",
        "            d_model, n_heads, dropout=dropout, is_causal=False\n",
        "        )\n",
        "\n",
        "        # ---- Bloque 3: FFN ----\n",
        "        # LN antes del sub-bloque (Pre-LN)\n",
        "        self.ln3 = nn.LayerNorm(d_model)\n",
        "        self.ffn = FeedForward(d_model, ffn_hidden, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, enc_out):\n",
        "        \"\"\"\n",
        "        x:       (B, T_dec, d_model)  estados/embeddings del decoder (entrada parcial)\n",
        "        enc_out: (B, T_enc, d_model)  salida del encoder (memoria)\n",
        "        devuelve:\n",
        "        x:       (B, T_dec, d_model)  salida del decoder layer\n",
        "        \"\"\"\n",
        "\n",
        "        # 1) Masked self-attention (causal)\n",
        "        # Normalizamos x -> aplicamos self-attn -> residual\n",
        "        h, _ = self.self_attn(self.ln1(x))  # h: (B, T_dec, d_model)\n",
        "        x = x + h\n",
        "\n",
        "        # 2) Cross-attention (Q = x, K/V = enc_out)\n",
        "        # Normalizamos x -> aplicamos cross-attn con kv=enc_out -> residual\n",
        "        h, _ = self.cross_attn(self.ln2(x), kv=enc_out)  # h: (B, T_dec, d_model)\n",
        "        x = x + h\n",
        "\n",
        "        # 3) Feed-Forward Network\n",
        "        # Normalizamos -> FFN -> residual\n",
        "        x = x + self.ffn(self.ln3(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Test de shapes\n",
        "# -------------------------\n",
        "dec_layer = TransformerDecoderLayer(\n",
        "    d_model=32, n_heads=4, ffn_hidden=64, dropout=0.1, max_seq_len=64\n",
        ")\n",
        "\n",
        "x = torch.randn(2, 6, 32)       # (B=2, T_dec=6, d_model=32)\n",
        "enc_out = torch.randn(2, 8, 32) # (B=2, T_enc=8, d_model=32)\n",
        "\n",
        "y = dec_layer(x, enc_out)\n",
        "\n",
        "print('dec layer out:', y.shape)  # esperado: (2, 6, 32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gSz-b2qFjQI",
        "outputId": "1673ff4d-79e5-4bfb-8a4b-4aaef053dff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dec layer out: torch.Size([2, 6, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Decoder (stack)\n",
        "Apilamos N capas de decoder y normalizamos al final."
      ],
      "metadata": {
        "id": "1ovC9wMoF5mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder Transformer: pila de capas TransformerDecoderLayer.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_layers, d_model, n_heads, ffn_hidden,\n",
        "                 dropout=0.0, max_seq_len=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        # Pila de capas decoder (cada una con parámetros independientes)\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerDecoderLayer(\n",
        "                d_model=d_model,\n",
        "                n_heads=n_heads,\n",
        "                ffn_hidden=ffn_hidden,\n",
        "                dropout=dropout,\n",
        "                max_seq_len=max_seq_len\n",
        "            )\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        # Normalización final\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_out):\n",
        "        \"\"\"\n",
        "        x:       (B, T_dec, d_model)  tokens/estados del decoder\n",
        "        enc_out: (B, T_enc, d_model)  salida del encoder (memoria)\n",
        "        devuelve:\n",
        "        out:     (B, T_dec, d_model)\n",
        "        \"\"\"\n",
        "        # Pasamos por todas las capas del decoder\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out)\n",
        "\n",
        "        # Normalización final\n",
        "        return self.ln(x)\n",
        "\n",
        "dec = Decoder(n_layers=2, d_model=32, n_heads=4, ffn_hidden=64, dropout=0.1, max_seq_len=64)\n",
        "x = torch.randn(2, 6, 32)\n",
        "enc_out = torch.randn(2, 8, 32)\n",
        "y = dec(x, enc_out)\n",
        "print('decoder out:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgZHymMeF7eZ",
        "outputId": "387a3fa9-62e1-4b34-dffa-8caab32aa194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder out: torch.Size([2, 6, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) Transformer completo (Encoder–Decoder) mini\n",
        "Incluimos:\n",
        "- Embedding de tokens\n",
        "- Positional encoding\n",
        "- Encoder\n",
        "- Decoder\n",
        "- Proyección final a vocab (lm_head)\n",
        "\n",
        "Para que sea autocontenido, hacemos un vocab mini y datos pequeños."
      ],
      "metadata": {
        "id": "iVHQcmhRGMDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Mini Transformer Encoder-Decoder (seq2seq) para modelado de tokens.\n",
        "\n",
        "    Flujo:\n",
        "      src_idx (B,S) -> tok_emb + pos_enc -> Encoder -> enc_out (B,S,d)\n",
        "      tgt_idx (B,T) -> tok_emb + pos_enc -> Decoder (con cross-attn a enc_out) -> dec_out (B,T,d)\n",
        "      dec_out -> lm_head -> logits (B,T,vocab)\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, max_len, d_model=64, n_heads=4,\n",
        "                 n_layers=2, ffn_hidden=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Embedding de tokens: ids -> vectores (d_model)\n",
        "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Positional encoding sinusoidal (no entrenable)\n",
        "        self.pos_enc = PositionalEncoding(max_len, d_model)\n",
        "\n",
        "        # Dropout aplicado a las representaciones de entrada (emb + pos)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        # Encoder: pila de TransformerEncoderLayer (self-attn no causal)\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, ffn_hidden, dropout)\n",
        "\n",
        "        # Decoder: pila de TransformerDecoderLayer:\n",
        "        # - self-attn causal (autoregresivo)\n",
        "        # - cross-attn hacia enc_out\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, ffn_hidden, dropout, max_seq_len=max_len)\n",
        "\n",
        "        # Cabeza de salida a vocabulario: (d_model -> vocab_size)\n",
        "        # bias=False es común en LM heads (y a veces se comparte con embeddings)\n",
        "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, src_idx, tgt_idx, tgt_targets=None):\n",
        "        \"\"\"\n",
        "        src_idx:     (B, S) ids fuente (entrada al encoder)\n",
        "        tgt_idx:     (B, T) ids del decoder (tokens vistos hasta ahora: teacher forcing)\n",
        "        tgt_targets: (B, T) ids objetivo (lo que queremos predecir en cada paso)\n",
        "                     Si se pasa, devolvemos también la loss.\n",
        "\n",
        "        Devuelve:\n",
        "          logits: (B, T, vocab_size)\n",
        "          loss:   escalar o None\n",
        "        \"\"\"\n",
        "        # Comprobaciones de tamaño\n",
        "        B, S = src_idx.shape\n",
        "        B2, T = tgt_idx.shape\n",
        "        assert B == B2\n",
        "        assert S <= self.max_len and T <= self.max_len\n",
        "\n",
        "        # -------------------------\n",
        "        # Encoder\n",
        "        # -------------------------\n",
        "        # 1) Token embedding: (B,S) -> (B,S,d)\n",
        "        # 2) Sumar positional encoding: (B,S,d)\n",
        "        # 3) Dropout\n",
        "        src = self.drop(self.pos_enc(self.tok_emb(src_idx)))   # (B,S,d_model)\n",
        "\n",
        "        # Encoder produce una representación contextual por posición\n",
        "        enc_out = self.encoder(src)                            # (B,S,d_model)\n",
        "\n",
        "        # -------------------------\n",
        "        # Decoder\n",
        "        # -------------------------\n",
        "        # Igual para el decoder:\n",
        "        # embeddings + pos enc + dropout\n",
        "        tgt = self.drop(self.pos_enc(self.tok_emb(tgt_idx)))   # (B,T,d_model)\n",
        "\n",
        "        # Decoder usa:\n",
        "        # - self-attn causal dentro del tgt (no mirar al futuro)\n",
        "        # - cross-attn con enc_out (mirar al src)\n",
        "        dec_out = self.decoder(tgt, enc_out)                   # (B,T,d_model)\n",
        "\n",
        "        # -------------------------\n",
        "        # Proyección a vocabulario\n",
        "        # -------------------------\n",
        "        logits = self.lm_head(dec_out)                         # (B,T,vocab_size)\n",
        "\n",
        "        # -------------------------\n",
        "        # Loss (opcional)\n",
        "        # -------------------------\n",
        "        loss = None\n",
        "        if tgt_targets is not None:\n",
        "            # CrossEntropyLoss espera:\n",
        "            # logits: (N, C) y targets: (N,)\n",
        "            # Por eso aplanamos (B,T, vocab) -> (B*T, vocab) y (B,T) -> (B*T)\n",
        "            loss = F.cross_entropy(\n",
        "                logits.reshape(-1, logits.size(-1)),\n",
        "                tgt_targets.reshape(-1)\n",
        "            )\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Mini prueba de shapes\n",
        "# -------------------------\n",
        "model = MiniTransformer(vocab_size=50, max_len=32, d_model=64, n_heads=4, n_layers=2).to(device)\n",
        "\n",
        "# src: (B=2, S=10)\n",
        "src = torch.randint(0, 50, (2, 10)).to(device)\n",
        "\n",
        "# tgt: (B=2, T=8)\n",
        "tgt = torch.randint(0, 50, (2, 8)).to(device)\n",
        "\n",
        "logits, _ = model(src, tgt)\n",
        "\n",
        "print('logits:', logits.shape)  # esperado: (2, 8, 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1zg7d4CGNtY",
        "outputId": "adbe4b68-ea7b-4fe1-9e35-9e362f62cc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: torch.Size([2, 8, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo de uso: Traducción de números\n",
        "\n",
        "Construimos una tarea artificial para entrenar rápido:\n",
        "- Entrada: secuencia de dígitos (0-9)\n",
        "- Salida: secuencia \"traducida\" (dígito + 10) (solo para tener un mapeo)\n",
        "\n",
        "Esto nos permite practicar el pipeline encoder-decoder sin datasets externos."
      ],
      "metadata": {
        "id": "sXR6G2CRGhKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAD, BOS, EOS = 0, 1, 2\n",
        "\n",
        "def make_toy_batch(batch_size=32, min_len=3, max_len=8, vocab_size=32):\n",
        "    \"\"\"\n",
        "    Crea un batch sintético para un Transformer encoder-decoder.\n",
        "\n",
        "    La tarea es \"traducir\" una secuencia de dígitos a otro vocabulario.\n",
        "    \"\"\"\n",
        "    src_seqs = []      # entradas del encoder\n",
        "    tgt_in_seqs = []   # entradas del decoder (con BOS)\n",
        "    tgt_out_seqs = []  # objetivos del decoder (con EOS)\n",
        "\n",
        "    for _ in range(batch_size):\n",
        "        # Longitud aleatoria de la secuencia\n",
        "        L = random.randint(min_len, max_len)\n",
        "\n",
        "        # Dígitos aleatorios (0..9)\n",
        "        digits = [random.randint(0, 9) for _ in range(L)]\n",
        "\n",
        "        # Encoder input:\n",
        "        # dígitos codificados en 3..12 + EOS\n",
        "        src = [3 + d for d in digits] + [EOS]\n",
        "\n",
        "        # Decoder target:\n",
        "        # dígitos \"traducidos\" en 13..22 + EOS\n",
        "        tgt_out = [13 + d for d in digits] + [EOS]\n",
        "\n",
        "        # Decoder input (teacher forcing):\n",
        "        # BOS + tokens traducidos (sin EOS)\n",
        "        tgt_in = [BOS] + [13 + d for d in digits]\n",
        "\n",
        "        src_seqs.append(src)\n",
        "        tgt_in_seqs.append(tgt_in)\n",
        "        tgt_out_seqs.append(tgt_out)\n",
        "\n",
        "    # Función de padding a la longitud máxima del batch\n",
        "    def pad(seqs, pad_id=PAD):\n",
        "        T = max(len(s) for s in seqs)\n",
        "        out = torch.full((len(seqs), T), pad_id, dtype=torch.long)\n",
        "        for i, s in enumerate(seqs):\n",
        "            out[i, :len(s)] = torch.tensor(s)\n",
        "        return out\n",
        "\n",
        "    # Devolvemos tensores (B, T)\n",
        "    return pad(src_seqs), pad(tgt_in_seqs), pad(tgt_out_seqs)\n",
        "\n",
        "\n",
        "# Ejemplo de batch pequeño\n",
        "src, tgt_in, tgt_out = make_toy_batch(batch_size=4)\n",
        "\n",
        "print('src:\\n', src)\n",
        "print('tgt_in:\\n', tgt_in)\n",
        "print('tgt_out:\\n', tgt_out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AaVHlOTGnLk",
        "outputId": "f8ee44b3-1fd2-4b45-99ef-25d111cc3c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src:\n",
            " tensor([[ 4,  3,  7,  6,  6,  5,  4, 11,  2],\n",
            "        [12,  9,  3,  2,  0,  0,  0,  0,  0],\n",
            "        [ 4,  6,  6,  2,  0,  0,  0,  0,  0],\n",
            "        [12,  3, 11,  6, 11,  9,  6,  2,  0]])\n",
            "tgt_in:\n",
            " tensor([[ 1, 14, 13, 17, 16, 16, 15, 14, 21],\n",
            "        [ 1, 22, 19, 13,  0,  0,  0,  0,  0],\n",
            "        [ 1, 14, 16, 16,  0,  0,  0,  0,  0],\n",
            "        [ 1, 22, 13, 21, 16, 21, 19, 16,  0]])\n",
            "tgt_out:\n",
            " tensor([[14, 13, 17, 16, 16, 15, 14, 21,  2],\n",
            "        [22, 19, 13,  2,  0,  0,  0,  0,  0],\n",
            "        [14, 16, 16,  2,  0,  0,  0,  0,  0],\n",
            "        [22, 13, 21, 16, 21, 19, 16,  2,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12) Entrenamiento rápido\n",
        "Objetivo: minimizar cross-entropy del decoder para predecir `tgt_out` dado `tgt_in` y `enc_out`.\n",
        "Esto es teacher forcing en traducción."
      ],
      "metadata": {
        "id": "ezBmxd8XG2Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toy_vocab_size = 32\n",
        "\n",
        "# Inicializamos el modelo Transformer encoder-decoder\n",
        "model = MiniTransformer(\n",
        "    vocab_size=toy_vocab_size,\n",
        "    max_len=32,\n",
        "    d_model=64,\n",
        "    n_heads=4,\n",
        "    n_layers=2,\n",
        "    ffn_hidden=128,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Optimizador Adam (típico en Transformers)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "# Para guardar la evolución de la loss\n",
        "loss_hist = []\n",
        "\n",
        "# Entrenamiento\n",
        "for step in range(200):\n",
        "    model.train()\n",
        "\n",
        "    # Batch sintético (teacher forcing)\n",
        "    src, tgt_in, tgt_out = make_toy_batch(batch_size=64)\n",
        "    src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "    # Reset de gradientes\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # Forward + loss\n",
        "    _, loss = model(src, tgt_in, tgt_targets=tgt_out)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Paso del optimizador\n",
        "    opt.step()\n",
        "\n",
        "    # Guardamos loss\n",
        "    loss_hist.append(loss.item())\n",
        "\n",
        "    # Logging cada 50 pasos\n",
        "    if (step + 1) % 50 == 0:\n",
        "        print(f'step {step+1:03d} | loss {loss.item():.4f}')\n",
        "\n",
        "# Gráfica de la loss\n",
        "plt.figure()\n",
        "plt.plot(loss_hist)\n",
        "plt.xlabel('step')\n",
        "plt.ylabel('loss')\n",
        "plt.title('seq2seq training loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "Hch41297G0HZ",
        "outputId": "5735acf9-7124-4a79-e799-e6b30c04f4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 050 | loss 1.9475\n",
            "step 100 | loss 1.6937\n",
            "step 150 | loss 1.2231\n",
            "step 200 | loss 1.0704\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdSBJREFUeJzt3Xd4E/f9B/C35CF5Sd7beLLMMGBGzAoEwkwCIaMlaSE7JJBmNUn5tQlkkpKmSZpQkjaDtNkLaAaEvfcwG4PBC+8peUqWdL8/Tne28MTYlizer+fRE3Q6nb6HAL/z+S6FIAgCiIiIiJyE0t4NICIiIupMDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORWGGyIiInIqDDdEdE1TKBRYunRph94bExODe+65p1Pb015X024iZ8dwQ3SNqKmpwYoVKzBlyhSEhYXBx8cHQ4cOxcqVK2E2m+3dvBb98ssv/CFORFfE1d4NIKLucfHiRTz22GOYNGkSnnrqKWg0Gvz666949NFHsW/fPnz66af2bmKzfvnlF6xYsaLLAk5tbS1cXTv2T2FaWhqUSv4/IpGjYbghukaEhobixIkTGDBggHzs4Ycfxn333YdPPvkEzz//PBISEuzYwqtnMplgsVjg7u7e7veo1eoOf55Kperwe4mo6/B/OYjsoLKyEk888QRiYmKgUqkQHByMG2+8EUeOHLE5b//+/Zg2bRq0Wi08PT1x/fXXY/fu3U2ut2vXLowYMQJqtRrx8fH44IMPsHTpUigUCvmcwMBAm2AjufXWWwEAZ86ckY/V19fjxRdfRO/evaFWqxEQEICxY8di48aNNu89e/Ysbr/9dvj7+0OtVmP48OH43//+1+QzTp06hRtuuAEeHh6IjIzEK6+8go8//hgKhQKZmZkt/j7dc889WLFiBQBxjIn0AIDMzEwoFAr87W9/w9tvv434+HioVCqcPn0aRqMRL7zwApKTk6HVauHl5YVx48Zh69atTT7j8rEr0u9beno67rnnHvj6+kKr1eLee+9FTU2NzXsvH3OzatUqKBQK7N69G0899RSCgoLg5eWFW2+9FcXFxTbvtVgsWLp0KcLDw+Hp6YmJEyfi9OnTVzWO5+jRo5g+fTo0Gg28vb0xadIk7Nu3z+ac9ny3BQUFuPfeexEZGQmVSoWwsDDMmjWr1e+KyJGwckNkBwsWLMB3332HRYsWITExEaWlpdi1axfOnDmDYcOGAQC2bNmC6dOnIzk5GUuWLIFSqcQnn3yCG264ATt37sTIkSMBACdOnMCUKVMQFBSEpUuXwmQyYcmSJQgJCWlXWwoKCgCI4UeydOlSLFu2DA888ABGjhwJvV6PQ4cO4ciRI7jxxhsBiIFlzJgxiIiIwJ/+9Cd4eXnhm2++wezZs/H999/LoamgoAATJ06EyWSSz/vXv/4FDw+PNtv28MMPIy8vDxs3bsR///vfZs/55JNPUFdXh4ceeggqlQr+/v7Q6/X48MMPMXfuXDz44IOorKzERx99hKlTp+LAgQMYMmRIm5995513IjY2FsuWLcORI0fw4YcfIjg4GH/961/bfO9jjz0GPz8/LFmyBJmZmXj77bexaNEifP311/I5ixcvxvLly3HzzTdj6tSpOHbsGKZOnYq6uro2r9+cU6dOYdy4cdBoNHj22Wfh5uaGDz74ABMmTMD27dsxatQoAO37bm+77TacOnUKjz32GGJiYlBUVISNGzciOzsbMTExHWofUbcSiKjbabVaYeHChS2+brFYhN69ewtTp04VLBaLfLympkaIjY0VbrzxRvnY7NmzBbVaLWRlZcnHTp8+Lbi4uAht/RU3GAxCYmKiEBsbK9TX18vHk5KShJkzZ7b63kmTJgmDBg0S6urqbNo9evRooXfv3vKxJ554QgAg7N+/Xz5WVFQkaLVaAYCQkZHR6ucsXLiw2fvIyMgQAAgajUYoKiqyec1kMgkGg8HmWHl5uRASEiLcd999NscBCEuWLJGfL1myRADQ5Lxbb71VCAgIsDkWHR0tzJ8/X37+ySefCACEyZMn23xvTz75pODi4iJUVFQIgiAIBQUFgqurqzB79myb6y1dulQAYHPNllze7tmzZwvu7u7ChQsX5GN5eXmCj4+PMH78ePlYW99teXm5AEB444032mwDkaNitxSRHfj6+mL//v3Iy8tr9vXU1FScP38ed911F0pLS1FSUoKSkhJUV1dj0qRJ2LFjBywWC8xmM3799VfMnj0bvXr1kt/fv39/TJ06tc12LFq0CKdPn8Z7771nM6jW19cXp06dwvnz55t9X1lZGbZs2YI777wTlZWVcvtKS0sxdepUnD9/Hrm5uQDEAcHXXXedXGkCgKCgINx9993t+r1qy2233YagoCCbYy4uLvK4G4vFgrKyMphMJgwfPrxJ119LFixYYPN83LhxKC0thV6vb/O9Dz30kE2X4Lhx42A2m5GVlQUA2Lx5M0wmEx599FGb9z322GPtatvlzGYzNmzYgNmzZyMuLk4+HhYWhrvuugu7du2S293Wd+vh4QF3d3ds27YN5eXlHWoPkb0x3BDZwfLly3Hy5ElERUVh5MiRWLp0KS5evCi/Lv3gmT9/PoKCgmweH374IQwGA3Q6HYqLi1FbW4vevXs3+Yy+ffu22oY33ngD//73v/Hyyy9jxowZNq+99NJLqKioQJ8+fTBo0CA888wzOH78uPx6eno6BEHA888/36R9S5YsAQAUFRUBALKysjrUvvaKjY1t9vinn36KwYMHy+NKgoKC8PPPP0On07Xruo3DIgD4+fkBQLt+4Lf1XinkXD6A29/fXz73ShQXF6OmpqbZ39P+/fvDYrEgJycHQNvfrUqlwl//+lesW7cOISEhGD9+PJYvXy53XxL1BAw3RHZw55134uLFi3j33XcRHh6ON954AwMGDMC6desAiNUGQAwgGzdubPbh7e3d4c9ftWoVnnvuOSxYsAB/+ctfmrw+fvx4XLhwAR9//DEGDhyIDz/8EMOGDcOHH35o074//vGPLbavu2ZeNTd257PPPsM999yD+Ph4fPTRR1i/fj02btyIG264QW57W1xcXJo9LghCl763q7X13QLAE088gXPnzmHZsmVQq9V4/vnn0b9/fxw9etSOLSdqPw4oJrKTsLAwPProo3j00UdRVFSEYcOG4dVXX8X06dMRHx8PANBoNJg8eXKL1wgKCoKHh0ezXQxpaWnNvmft2rV44IEHMGfOHHkmUnP8/f1x77334t5770VVVRXGjx+PpUuX4oEHHpC7Ptzc3FptHwBER0dfUfsu17h7p72+++47xMXF4YcffrB5v1RVsrfo6GgAYgWsceWptLS0Q11BQUFB8PT0bPb39OzZs1AqlYiKipKPtfbdSuLj4/H000/j6aefxvnz5zFkyBC8+eab+Oyzz664fUTdjZUbom5mNpubdI0EBwcjPDwcBoMBAJCcnIz4+Hj87W9/Q1VVVZNrSNOKXVxcMHXqVKxZswbZ2dny62fOnMGvv/7a5H07duzAb3/7W4wfPx6ff/55iwvQlZaW2jz39vZGQkKC3L7g4GBMmDABH3zwAfLz81tsHwDMmDED+/btw4EDB2xe//zzz5v97Mt5eXkBACoqKtp1PtBQOWlcKdm/fz/27t3b7mt0pUmTJsHV1RUrV660Of7ee+916HouLi6YMmUK1q5dazNdu7CwEF988QXGjh0LjUYDoO3vtqampsmMrfj4ePj4+MjnEDk6Vm6IulllZSUiIyNx++23IykpCd7e3ti0aRMOHjyIN998EwCgVCrx4YcfYvr06RgwYADuvfdeREREIDc3F1u3boVGo8GPP/4IAHjxxRexfv16jBs3Do8++ihMJhPeffddDBgwwGYsRVZWFm655RYoFArcfvvt+Pbbb23aNXjwYAwePBgAkJiYiAkTJiA5ORn+/v44dOiQPHVdsmLFCowdOxaDBg3Cgw8+iLi4OBQWFmLv3r24dOkSjh07BgB49tln8d///hfTpk3D448/Lk8Fj46OtmlfS5KTkwEAf/jDHzB16lS4uLjgt7/9bavvuemmm/DDDz/g1ltvxcyZM5GRkYH3338fiYmJzYbF7hYSEoLHH38cb775Jm655RZMmzYNx44dw7p16xAYGNihatUrr7yCjRs3YuzYsXj00Ufh6uqKDz74AAaDAcuXL5fPa+u7PXfuHCZNmoQ777wTiYmJcHV1xerVq1FYWNjm7zuRw7DvZC2ia4/BYBCeeeYZISkpSfDx8RG8vLyEpKQk4Z///GeTc48ePSrMmTNHCAgIEFQqlRAdHS3ceeedwubNm23O2759u5CcnCy4u7sLcXFxwvvvvy9PaZZs3bpVANDio/G04ldeeUUYOXKk4OvrK3h4eAj9+vUTXn31VcFoNNp87oULF4R58+YJoaGhgpubmxARESHcdNNNwnfffWdz3vHjx4Xrr79eUKvVQkREhPDyyy8LH330UbumgptMJuGxxx4TgoKCBIVCId+TNBW8uSnLFotFeO2114To6GhBpVIJQ4cOFX766Sdh/vz5QnR0tM25l9+79PtWXFxsc540zbtxe1uaCn7w4EGb90q/91u3brW5r+eff14IDQ0VPDw8hBtuuEE4c+aMEBAQICxYsKDV35Pm2i0IgnDkyBFh6tSpgre3t+Dp6SlMnDhR2LNnj805bX23JSUlwsKFC4V+/foJXl5eglarFUaNGiV88803bbaJyFEoBMEBRrgRUadbunQpXnzxRYcYxNqcVatW4d5770VGRgYXhrOqqKiAn58fXnnlFfz5z3+2d3OIeiyOuSEisoPa2tomx95++20AwIQJE7q3MUROhmNuiIjs4Ouvv8aqVaswY8YMeHt7Y9euXfjyyy8xZcoUjBkzxt7NI+rRGG6IiOxg8ODBcHV1xfLly6HX6+VBxq+88oq9m0bU43HMDRERETkVjrkhIiIip8JwQ0RERE7lmhtzY7FYkJeXBx8fnw4tlEVERETdTxAEVFZWIjw8vMXV1SXXXLjJy8uz2WOFiIiIeo6cnBxERka2es41F258fHwAiL850l4rRERE5Nj0ej2ioqLkn+OtuebCjdQVpdFoGG6IiIh6mPYMKeGAYiIiInIqDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORWGGyIiInIqDDdERETkVBhuiIiIyKkw3BAREZFTYbjpRGXVRqQVVNq7GURERNc0hptOsuFUAYa9vBHPfHfM3k0hIiK6pjHcdJKBEVoAwKk8PaoMJju3hoiI6NrFcNNJwn09EOHrAbNFwJGscns3h4iI6JrFcNOJRsX6AwAOZpbZuSVERETXLoabTjTCGm4OZDDcEBER2QvDTScaESOGm6M5FTCYzHZuDRER0bWJ4aYTxQd5IcDLHUaTBScu6ezdHCIiomsSw00nUigUcvXmAMfdEBER2QXDTSfjuBsiIiL7YrjpZNKMqcOZ5TBbBDu3hoiI6NrDcNPJ+odp4OnugkqDCRkl1fZuDhER0TWH4aaTuSgViAnwAgBklTLcEBERdTeGmy4QHeAJAMgsrbFzS4iIiK49DDddINpauclm5YaIiKjb2TXcrFy5EoMHD4ZGo4FGo0FKSgrWrVvX4vmrVq2CQqGweajV6m5scfvEsHJDRERkN672/PDIyEi8/vrr6N27NwRBwKeffopZs2bh6NGjGDBgQLPv0Wg0SEtLk58rFIruam679bKGm+wyhhsiIqLuZtdwc/PNN9s8f/XVV7Fy5Urs27evxXCjUCgQGhraHc3rMGlAcU5ZDUxmC1xd2PtHRETUXRzmp67ZbMZXX32F6upqpKSktHheVVUVoqOjERUVhVmzZuHUqVPd2Mr2CdWo4e6qhMkiIK+izt7NISIiuqbYPdycOHEC3t7eUKlUWLBgAVavXo3ExMRmz+3bty8+/vhjrF27Fp999hksFgtGjx6NS5cutXh9g8EAvV5v8+hqSqUCvfzFrqmsMg4qJiIi6k52Dzd9+/ZFamoq9u/fj0ceeQTz58/H6dOnmz03JSUF8+bNw5AhQ3D99dfjhx9+QFBQED744IMWr79s2TJotVr5ERUV1VW3YoODiomIiOzD7uHG3d0dCQkJSE5OxrJly5CUlIR33nmnXe91c3PD0KFDkZ6e3uI5ixcvhk6nkx85OTmd1fRWcTo4ERGRfdg93FzOYrHAYDC061yz2YwTJ04gLCysxXNUKpU81Vx6dAcu5EdERGQfdp0ttXjxYkyfPh29evVCZWUlvvjiC2zbtg2//vorAGDevHmIiIjAsmXLAAAvvfQSrrvuOiQkJKCiogJvvPEGsrKy8MADD9jzNpoVzS0YiIiI7MKu4aaoqAjz5s1Dfn4+tFotBg8ejF9//RU33ngjACA7OxtKZUNxqby8HA8++CAKCgrg5+eH5ORk7Nmzp8UByPYU02itG4tFgFLpeOvxEBEROSOFIAiCvRvRnfR6PbRaLXQ6XZd2UdWbLej3/HqYLQL2LZ6EUK3jraRMRETUU1zJz2+HG3PjLNxclIj08wDArikiIqLuxHDThaRxNxklDDdERETdheGmC/UJ9gYAnC2otHNLiIiIrh0MN12oX5jYJ3gmv+tXRSYiIiIRw00X6h/mA0Cs3Fxj47aJiIjshuGmCyUEe8NVqYCuth75Om6gSURE1B0YbrqQytUF8UHiuBt2TREREXUPhpsu1rhrioiIiLoew00X628dVHyalRsiIqJuwXDTxThjioiIqHsx3HQxqVsqs6QatUaznVtDRETk/BhuuliwjxqB3u6wCMC5Qo67ISIi6moMN92gXyi7poiIiLoLw003kLqmGG6IiIi6HsNNN+gTIoabC8XcQJOIiKirMdx0g9hA7g5ORETUXRhuukGMNdzk6WpRV88ZU0RERF2J4aYbBHi5w1vlCkEALpXX2Ls5RERETo3hphsoFArEBHoCADJKGG6IiIi6EsNNN4kJELumMjnuhoiIqEsx3HQTOdyUMtwQERF1JYabbiINKma4ISIi6loMN90k1jrmJpNjboiIiLoUw003iQ7gdHAiIqLuwHDTTQK83OFjnQ6eU8bqDRERUVdhuOkm4nRwrlRMRETU1RhuulF0gHXcDQcVExERdRmGm24UK8+YYrcUERFRV2G46UZcyI+IiKjrMdx0I2kLhjP5epRXG+3cGiIiIufEcNONBoRrEenngfKaeiz47DCMJou9m0REROR0GG66kdrNBR/NHwFvlSv2Z5Thz6tP2LtJRERETofhppv1DfXBe3cNhVIBfHv4EtKLKu3dJCIiIqfCcGMHE/oGo3+YBgCQU1Zr59YQERE5F4YbOwnyUQEAiisNdm4JERGRc2G4sZNga7gpqqyzc0uIiIicC8ONnbByQ0RE1DUYbuwkyNsabqoYboiIiDoTw42dBGvUAFi5ISIi6mwMN3YSJI+5YbghIiLqTAw3diJ3SzHcEBERdSqGGzuRKjc1RjOqDSY7t4aIiMh5MNzYiZfKFV7uLgDYNUVERNSZGG7siNPBiYiIOh/DjR0x3BAREXU+hhs7CvYRp4NzlWIiIqLOw3BjR6zcEBERdT6GGztiuCEiIup8DDd2xIX8iIiIOh/DjR2xckNERNT5GG7siJtnEhERdT6GGzsK1ojhprTKALNFsHNriIiInINdw83KlSsxePBgaDQaaDQapKSkYN26da2+59tvv0W/fv2gVqsxaNAg/PLLL93U2s4X4KWCUgFYBKC0mtUbIiKizmDXcBMZGYnXX38dhw8fxqFDh3DDDTdg1qxZOHXqVLPn79mzB3PnzsX999+Po0ePYvbs2Zg9ezZOnjzZzS3vHC5KBfy9OO6GiIioMykEQXCo/hB/f3+88cYbuP/++5u89pvf/AbV1dX46aef5GPXXXcdhgwZgvfff79d19fr9dBqtdDpdNBoNJ3W7o6a8c5OnM7XY9W9IzChb7C9m0NEROSQruTnt8OMuTGbzfjqq69QXV2NlJSUZs/Zu3cvJk+ebHNs6tSp2Lt3b4vXNRgM0Ov1Ng9HwungREREncvu4ebEiRPw9vaGSqXCggULsHr1aiQmJjZ7bkFBAUJCQmyOhYSEoKCgoMXrL1u2DFqtVn5ERUV1avuvVoSfBwDgQEaZnVtCRETkHOwebvr27YvU1FTs378fjzzyCObPn4/Tp0932vUXL14MnU4nP3Jycjrt2p3htmGRAIC1qbnI19XauTVEREQ9n93Djbu7OxISEpCcnIxly5YhKSkJ77zzTrPnhoaGorCw0OZYYWEhQkNDW7y+SqWSZ2NJD0eSHO2HkbH+qDcL+HhXhr2bQ0RE1OPZPdxczmKxwGBofvxJSkoKNm/ebHNs48aNLY7R6SkeuT4eAPDF/mzoaurt3BoiIqKeza7hZvHixdixYwcyMzNx4sQJLF68GNu2bcPdd98NAJg3bx4WL14sn//4449j/fr1ePPNN3H27FksXboUhw4dwqJFi+x1C51iQt8g9Av1QbXRjM/2Z9m7OURERD2aXcNNUVER5s2bh759+2LSpEk4ePAgfv31V9x4440AgOzsbOTn58vnjx49Gl988QX+9a9/ISkpCd999x3WrFmDgQMH2usWOoVCocB9Y2IBABtOF7ZxNhEREbXG4da56WqOts6NJL2oCpP/vh0ebi449eJUKJUKezeJiIjIYfTIdW6udTEBnlC5KlFbb0Z2WY29m0NERNRjMdw4CFcXJXqHeAMAzhZU2rk1REREPRfDjQPpFyqW2c4WONYqykRERD0Jw40D6RfqAwBIY+WGiIiowxhuHEhD5YbhhoiIqKMYbhxIX2vlJrO0GjVGk51bQ0RE1DMx3DiQIB8VAr3dIQjA+cIqezeHiIioR2K4cTBS9YaDiomIiDqG4cbBcNwNERHR1WG4cTDSjKmz+Qw3REREHcFw42Aar3Vzje2MQURE1CkYbhxM7xBveLi5oLymHqfyOO6GiIjoSjHcOBi1mwvG9Q4EAGzkDuFERERXjOHGAd2YGAKA4YaIiKgjGG4c0A39gqFUAKfz9citqLV3c4iIiHoUhhsHFOCtQnK0HwBgE6s3REREV4ThxkFJXVObzjDcEBERXQmGGwc1ub8YbvZdLIW+rt7OrSEiIuo5GG4cVFyQN2IDvVBvFnA4q9zezSEiIuoxGG4cWN8QcbXijOJqO7eEiIio52C4cWCxQV4AgIwShhsiIqL2YrhxYLGBtuHGZLZgxdZ07L9Yas9mEREROTSGGwcWd1m42XSmCG/8moa7PtyPNUdz7dk0IiIih8Vw48Ckyk2erhZ19WYcu1QBADBbBDzxdSr+uzfTfo0jIiJyUAw3Dszfyx0atSsEAcgqrcGJSzoADQONX/zxNMqrjfZsIhERkcNhuHFgCoVCrt5cLK7CiVwx3PztjiTEBnrBZBGQaq3mEBERkYjhxsFJ4WbH+WLoauvh7qJE31AfDI3yBQCkZlfYr3FEREQOiOHGwcUGegMAfjlRAADoF+YDd1clhvbyBQAczamwU8uIiIgcE8ONg5PWutHVilswDIzQAgCGRIkbax7LqYDFItincURERA6I4cbBSdPBJYOt4aZfmA9UrkroauuRUcpF/oiIiCQMNw4u5rJwI1Vu3FyUGGT9NcfdEBERNWC4cXDeKlcE+6gAAO6uSvSxTgMH0GjcDTfWJCIikjDc9ADSjKn+oeJgYok07iaVg4qJiIhkDDc9QFyQOGNK6pKSDLFWbs7kV6LWaO7uZhERETkkhpse4IFxsbglKRwLro+3OR6uVSPYRwWzRcBbm86hxmiyUwuJiIgcB8NNDxAf5I1/zB2KKH9Pm+MKhQK3J0cCAP614yIm/m0bjmZz/A0REV3bGG56uGem9sU/7x6GSD8PFOoN+GJ/tr2bREREZFcMNz2cQqHAjEFheGJyHwBAvq7Ozi0iIiKyL4YbJxGuVQMA8nS1dm4JERGRfTHcOIkwXw8AQIGuDoLA7RiIiOjaxXDjJMKslZsaoxn6Ws6aIiKiaxfDjZNQu7nAz9MNQEPX1OvrzuKxL49yY00iIrqmMNw4kTCt2DWVr6tFrdGMD3ZcwI/H8nCxpMrOLSMiIuo+DDdOJNxX7JrK19XhYkkVpKE3BTqDHVtFRETUvVzt3QDqPHLlpqIO3qqGak2BntPDiYjo2sFw40RCG00HVyoajhdwejgREV1DGG6ciNQtVaCrg6HeIh/nwn5ERHQtYbhxIg0DiutQWmWUjxeyW4qIiK4hDDdOJNwabvIqatF4HT9WboiI6FrCcONEQrQqAIDBZLE5zsoNERFdSzgV3ImoXF0Q6O0uPw/ViGNwSqqMMJjM9moWERFRt2K4cTLSuBsAGB7jB3dX8Ssu0otr3ZRUGWDmisVEROTE7Bpuli1bhhEjRsDHxwfBwcGYPXs20tLSWn3PqlWroFAobB5qtbqbWuz4pD2mACAh2Fuu3hTo67AtrQjDX9mEf25Nt1fziIiIupxdw8327duxcOFC7Nu3Dxs3bkR9fT2mTJmC6urqVt+n0WiQn58vP7KysrqpxY6vSbjRNkwPX3+yAACw+WyRXdpGRETUHew6oHj9+vU2z1etWoXg4GAcPnwY48ePb/F9CoUCoaGhXd28HinMt6FbKj6oUeVGV4ej2RUAgLSCSlgsApSNV/ojIiJyEg415kan0wEA/P39Wz2vqqoK0dHRiIqKwqxZs3Dq1KkWzzUYDNDr9TYPZyZVbpQKIDbQS36eXlSFc0WVAIDaejOyy2rs1kYiIqKu5DDhxmKx4IknnsCYMWMwcODAFs/r27cvPv74Y6xduxafffYZLBYLRo8ejUuXLjV7/rJly6DVauVHVFRUV92CQ4gN9AIAxAV5Q+3mIndLbTpTaLP2zdkC5w55RER07VIIguAQU2ceeeQRrFu3Drt27UJkZGS731dfX4/+/ftj7ty5ePnll5u8bjAYYDA07Iqt1+sRFRUFnU4HjUbTKW13JIIg4PsjuegX6oOBEVqsO5GPRz4/0uS8Jyb3xhOT+9ihhURERFdOr9dDq9W26+e3Qyzit2jRIvz000/YsWPHFQUbAHBzc8PQoUORnt78DCCVSgWVStUZzewRFAoFbk9u+D0M1drOJIv088Cl8lqcza/s7qYRERF1C7t2SwmCgEWLFmH16tXYsmULYmNjr/gaZrMZJ06cQFhYWBe0sOe7PNz8doTYLcduKSIiclZ2DTcLFy7EZ599hi+++AI+Pj4oKChAQUEBamtr5XPmzZuHxYsXy89feuklbNiwARcvXsSRI0fwu9/9DllZWXjggQfscQsOL8hbBWlSlLuLErdZqzpZZTWoNphszq0xmi5/OxERUY9j13CzcuVK6HQ6TJgwAWFhYfLj66+/ls/Jzs5Gfn6+/Ly8vBwPPvgg+vfvjxkzZkCv12PPnj1ITEy0xy04PFcXJYJ9xOpNYrgGYVoPBPmoIAjAucKGrql/7biAgUt+xY5zxfZqKhERUaew65ib9oxl3rZtm83zt956C2+99VYXtcg5hWjVKNDXYWgvXwBAv1AfFFcacLagEkN7+QEAtp8rhkUADmWWYXyfIDu2loiI6Oo4zFRw6joDw8VR5VJo6R8mPk8raKjcZBSLq0IXVxm7uXVERESdyyFmS1HXWnLzAMwfHYPewd4AxMoNAJzJFwcV1xrNyNPVAQCKKw3NX4SIiKiHYLi5Bri7KtEnxEd+3i9UrNycyddDEARkljbs5VVSxXBDREQ9G7ulrkEJwd5wc1FAX2fCpfJaZJQ0hBtWboiIqKdjuLkGNa7knMrT2YSbkipDuwZ6ExEROSqGm2vUAOsg41N5eptwYzBZUGngejdERNRzMdxcowZGaAE0DTcAu6aIiKhnY7i5RkmVm5O5Dd1S0krGJQw3RETUg3Uo3Hz66af4+eef5efPPvssfH19MXr0aGRlZXVa46jr9AvVQKEAiioNKKsW17aR1r8p5owpIiLqwToUbl577TV4eHgAAPbu3YsVK1Zg+fLlCAwMxJNPPtmpDaSu4aVyRVygl/w82EeF6ABPAB2r3Hy48yKmvLUdRfq6TmsjERFRR3Qo3OTk5CAhIQEAsGbNGtx222146KGHsGzZMuzcubNTG0hdZ0C4Vv51bKAXgrxVADpWufnmUA7OFVZhz4XSTmsfERFRR3Qo3Hh7e6O0VPwhtmHDBtx4440AALVabbOjNzk2adwNAMQFeSHQGm5KKq98C4Z86wrHRZWs3BARkX11aIXiG2+8EQ888ACGDh2Kc+fOYcaMGQCAU6dOISYmpjPbR13o8sqNRu0GoOXKjdFkwYlcHZIitXB1acjFVQYTKuvE6eNFeo7XISIi++pQ5WbFihVISUlBcXExvv/+ewQEBAAADh8+jLlz53ZqA6nrNK7cxAZ6I8jHWrlpIdz8a8cF3LZyDz7bZztovEDXUK0r4kwrIiKysw5Vbnx9ffHee+81Of7iiy9edYOo+/h5uaNfqA/Si6owIFwjr2/T0jo3J3PFjTaPZFfgnjENx6UuKQAo5IBiIiKysw5VbtavX49du3bJz1esWIEhQ4bgrrvuQnl5eac1jrreZw+Mwi+Pj0O4r4dN5aa5LRhyK8QKTXpRlc3xxuGGCwASEZG9dSjcPPPMM9Drxf+LP3HiBJ5++mnMmDEDGRkZeOqppzq1gdS1Ar1V8j5TAd7uAIB6swBdbX2Tcy+V1wAALpZUwWJpCD8FjcJN424p7lFFRET20KFwk5GRgcTERADA999/j5tuugmvvfYaVqxYgXXr1nVqA6n7qFxdoPWwDiq+rAJTbTChvEYMPHX1FrmKAwD5jcbcVBlMqDaYUFplwNi/bsXS/53qhpYTERE16FC4cXd3R02N+H/xmzZtwpQpUwAA/v7+ckWHeqZAa/Xm8hlTjcMMAKQXN3RNNe6WAsTqzf6MMuRW1OLnE/ld1FIiIqLmdSjcjB07Fk899RRefvllHDhwADNnzgQAnDt3DpGRkZ3aQOpe0ribyys3ueW24eZCo3E3BZeHG30dLlrDT3GlAQaTuSuaSkRE1KwOhZv33nsPrq6u+O6777By5UpEREQAANatW4dp06Z1agOpewX5qAEAJVW2C/lJ420kjQcVS5UbP0+xS6uw0oCLjXYavzz8EBERdaUOTQXv1asXfvrppybH33rrratuENmX1C2VU1aD/x3LQ5SfB4b28sMla7dUoLc7SqqMuGCtzNQYTfLg46QoX2xLK7ZWbhrCTW55LaIDvEBERNQdOhRuAMBsNmPNmjU4c+YMAGDAgAG45ZZb4OLi0mmNo+4ndUut2pOJVXsy4a1yxaG/TJa7pcb3CcIPR3Llyo1UtfFWuSIu0Bvb0opRXGmQu6WApuN1GvvP3kzEBXpjbO/ArrolIiK6xnQo3KSnp2PGjBnIzc1F3759AQDLli1DVFQUfv75Z8THx3dqI6n7RPh62DyvMphwMleHS9ZwM653IFYfzUV5TT1Kqwxyl1OoVo0QjRiMzhRUQm/djgEA8iqa75Y6k6/HC2tPIchHhYN/ntwVt0NERNegDo25+cMf/oD4+Hjk5OTgyJEjOHLkCLKzsxEbG4s//OEPnd1G6kZTEkPxzNS++Pe84bgxMQQAcDCzXK6+JAT5yAEovahKrtyEadUItoabQ5llNtfMs7531e4MXPfaZmRYx+NI1Z/iSgN0NU3X1SEiIuqIDoWb7du3Y/ny5fD395ePBQQE4PXXX8f27ds7rXHU/TzcXbBwYgJuTAzBqFjx+92VXizPnor080BCsDcA4EJxtbyvVKhGjWDrYOQao+3sqDzrOV8dzEGBvg6/nioAAGQ2GnScVVYNIiKiztChcKNSqVBZWdnkeFVVFdzd3a+6UeQYRsSI4WbvhVIAgKe7C3w93ZAQJIabyys3UreUpE+IeF5uRS0MJrNcqZGmkWeWNszAyihhuCEios7RoXBz00034aGHHsL+/fshCAIEQcC+ffuwYMEC3HLLLZ3dRrKTxHANPNxcIO20EOnnAYVCgXhr5eZgZpk8FifM10OeRi4ZmxAEQOyWOl9YBZP1QtICgJmljSo3pbZTzYmIiDqqQ+HmH//4B+Lj45GSkgK1Wg21Wo3Ro0cjISEBb7/9dic3kezFzUWJYdG+8nNprM3YhECo3ZQ4kavD9nPFAMQBxRq1K1SuDX+kxiQEABC3a9hzoUQ+fqGoCoIgIKtRuMlk5YaIiDpJh2ZL+fr6Yu3atUhPT5engvfv3x8JCQmd2jiyv+HR/tidLnZLRfp5AgCi/D3x9zuH4NHPj8jnhWnVUCgUCNaokFMmVnP6hWkQ5KNCcaUBm84Uyefq60zIKKm2WSiwcRWHiIjoarQ73LS12/fWrVvlX//973/veIvIoUjjbgAgwq9hmviMQWH445Q++NuGc1AogDCt+FqIjxo5ZbVQuykRplEj3NcDxZWGJjOotpwtsnmeyW4pIiLqJO0ON0ePHm3XeQqFosONIccztJcvXJQKmC0CIv1s18BZODEBKlcXqNyU8m7i0nTwmAAvKJUKRPp64FhOhTxuJ1SjRoG+DpvOFAIA+oX64GxBJcqqjdDV1svXISIi6qh2h5vGlRm6dnipXDGxbzB2ni9GUqSvzWsKhQIPjo+zOSZNB4+3zqgK920YZOyqVGDqgBB8ujcLBzPLAQADwrUorTaiuNKArNJqDL7sM4iIiK5UhwYU07Xl3blDsedPNyDK37PNc8f1FgcbT04MBgCEN1rxOD7IG4nhGgCA2VrKiQnwREyAeN3M0hp8uicTA15YjyPZ5S1+RlFlHVZsTYe+jgv/ERFRUx3eW4quHR7uLvBwb9+eYZP6h+DUi9PgohS7JxuHm/5hPnJFRxIT6IWsshoczCxHWoEeX+zPRrXRjP+l5mFYL79mP2Px9yew+WwRKutM+NP0fh28KyIiclas3FCnk4INYLtXVWK4pmm4CfBCbKC4Y/h/92ah3LoNw7FLFc1eO72oEputg5F3pRd3ZrOJiMhJMNxQl7Kt3Gjg5+WOAK+GVayjAz0Rbe2WarzZ5qk8PYwmS5Prfbgzw+acihpjk3OIiOjaxnBDXcrP0w2hGjXUbkoMDNcCgLzCcYCXOzRqN8QEeMnnu7sq4aNyhdFkQVqB7RYfRZV1+OFILgDAR+UKQWjYGoKIiEjCcENdSqFQ4LtHUvDjorHws1ZspK6pGGt3lPRfALh5cDiGRotjbVIv65r6794sGM0WDO3li9uSIwEAuxutfExERAQw3FA3iPTzRO8QH/l5UqRYwRlgnTnlrXJFXKAXFApg/uhoDLG+fiynwuY6q4+KVZsHxsZhdLy4tcOedFZuiIjIFmdLUbe7LTkSQT4qjIhtWP3443tGoLTaiMGRviiuNACwDTe6mnp5k86xvQMBAEoFcLGkGvm6WnmFZCIiIlZuqNu5uSgxqX8INOqG1YhjAr2QbO2OkhbySy+uQqV1LZtT+ToAQJS/B7QebtB6uGGQ9bzdrN4QEVEjDDfkcIJ8VIjw9YAgACdyxVBzOk8PAEgM08jnjZG7pjjuhoiIGjDckEMaEuULADiWYw03+VK40crnSN1aJ/N03ds4IiJyaAw35JCSosQQI+0mLlduwhsqNwnWWVeZpTXydg5EREQMN+SQxvUOAgDsTC9BWbUR6UVVABpmWAHiAoHuLkoYTRbkVdTapZ1EROR4GG7IIfUL9UFcoBeMJgtWbkuHySLA19MNYdqGXcZdlAr0kjfdrLZXU4mIyMEw3JBDUigUmDk4DADwn71ZAMTBxAqFwuY8aV+qjBIx3JzK0+HjXRnspiIiuoYx3JDDmjFIDDcG6x5TjWdKSeKs4eZisRhunv3uOF766TT2cOViIqJrFsMNOax+oT6IC2rYmmFARNNw07hyU1lXL8+qyq+o655GEhGRw2G4IYelUCgw01q9AWyngUsah5vUnAoI1t6o0mruFk5EdK1iuCGHdtPgcADW/acaVXEkUri5VF6DfRcbViourTJ0TwOJiMjh2DXcLFu2DCNGjICPjw+Cg4Mxe/ZspKWltfm+b7/9Fv369YNarcagQYPwyy+/dENryR76hvrgg98n48P5w+Hm0vSPa5CPCl7uLrAIwJqjefLxsssqN9UGE179+TReWHsStUZzl7ebiIjsx67hZvv27Vi4cCH27duHjRs3or6+HlOmTEF1dcvTevfs2YO5c+fi/vvvx9GjRzF79mzMnj0bJ0+e7MaWU3eaOiAU18UFNPuaQqFArLWik9torZvG3VInLulw07u78O+dGfjP3izcu+oAqgymrm00ERHZjUIQBIeZM1tcXIzg4GBs374d48ePb/ac3/zmN6iursZPP/0kH7vuuuswZMgQvP/++21+hl6vh1arhU6ng0bTdIAq9TyPfXkUPx7Lszk2KEKLHx8bi3xdLSb+bRvq6i0I1ahRZTChymDCkChffPngdfBwd7FTq4mI6Epcyc9vhxpzo9OJewT5+/u3eM7evXsxefJkm2NTp07F3r17mz3fYDBAr9fbPMi5SONuAEDrIe40Lo25Sc2uQF29BbGBXlj/xDh88eAo+Hq6ITWnAj8dz2v2ekRE1LM5TLixWCx44oknMGbMGAwcOLDF8woKChASEmJzLCQkBAUFBc2ev2zZMmi1WvkRFRXVqe0m+4sN9JR/fUO/YABit5QgCMjXiVPCE8M18PV0x+BIX8wZGgkAOJNf2f2NJSKiLucw4WbhwoU4efIkvvrqq0697uLFi6HT6eRHTk5Op16f7C820Fv+9ZREMfgaTBbUGM0o0IvhJlTTsG1D31Dx/HOFbYebk7k6XP/GVnx5ILszm0xERF3IIcLNokWL8NNPP2Hr1q2IjIxs9dzQ0FAUFhbaHCssLERoaGiz56tUKmg0GpsHOZe4IC+4uyjh7qLE6PhAqN3EP9alVUa5ctN4T6q+oeKfgbR2hJtXfz6DrNIaeQsIIiJyfHYNN4IgYNGiRVi9ejW2bNmC2NjYNt+TkpKCzZs32xzbuHEjUlJSuqqZ5OA0ajd8dM9wfHLvCGg93RDgpQIAlFYbUGgNN6GNwk3vYLFyU1xpaDJlvLE9F0qw17p2TlqBHpV19V11C0RE1InsGm4WLlyIzz77DF988QV8fHxQUFCAgoIC1NY2TOmdN28eFi9eLD9//PHHsX79erz55ps4e/Ysli5dikOHDmHRokX2uAVyEON6B2FMQiAAwN/LHYC41k2+Xvyz1Lhy46VyRZS/B4CWu6YEQcBbG8/Jzy0CkJpT0ey5pVUGzPnnbnZdERE5CLuGm5UrV0Kn02HChAkICwuTH19//bV8TnZ2NvLz8+Xno0ePxhdffIF//etfSEpKwnfffYc1a9a0OgiZri1SuCmpMqBQJ86aCmk05gYA+ob4AGgIN4IgoPGqCLvSS3AwsxzurkqMjhfX2DmcVd7s5206U4gj2RV4d/N5ONDKCkRE1yxXe354e34QbNu2rcmxO+64A3fccUcXtIicQYC3GG7OF1bBaLZAoQCCfWzDTZ8QH2w6U4S0gkqUVRtx6z93Iy7QCyt/lwyDyYK/rBEXhbx7VC/EBXljz4XSFsNNbrlYHcrT1SG7rAbRAU23iWjNyVwd/vjtMTwztS8m9Q9p+w1ERNQqu4Yboq4QYK3cSDuEB3qr4O5qW6TsG9pQufnqYDaySmuQVVqDRV8cgVKhQFZpDSJ8PfD4pN7Is+4wnppdAbNFgItSYXOtS+UN3ah7LpRecbj58VgezhZU4uuDOQw3RESdgOGGnI6/dUDxqTwx3DQebyPpY+2WSiuolKeLA8CmM0UAAHcXJVb+bhh8Pd3ho3aDl7sLKg0mnCusRP8w2xl3lxpt+7D3Qinmjux1Re29UFwFAEi3/peIiK6OQ0wFJ+pMUuVGVyvObrp8vA0gTh93USqgrzMhp6wWGrUr3rtrqFyVeeHmRAyO9AUAuCgVGNrLD0Dz425yG1Vu9l4sveJxNxeKxb3UsktrUG+2XNF7iYioKYYbcjrSmBtJc5UblauLzbYNtyVH4qbB4fh2QQpW3j0Md4+yrb4MixbDzZHLwk292YJ8nRhulApxevmFK6jAGE0WZJfVAABMFgFZpS1vGktERO3DcENOR5otJQltJtwADTOmAMhhZlgvP0wfFAaFwnZczXBruNlxvhhpBQ3Txwt0dbAIYjfWyFhxT7S9F0rb3dbssmqYLQ2VnvQidk0REV0thhtyOtIifpLmKjcA0D9MDDcjY/2REOzT7DmS4TF+iPD1QEmVETe/twurdmcAaBhMHOHngTHx4jo70sJ/7ZFeZFupkbqoiIio4xhuyOn4X9Yt1dyYGwD4fUoMHhwXi+W3DW7zmp7urli9cDRu6BcMo8mCpT+exslcHS6Vi11KEb4eSLGuh7PzfAmOtbDg3+UulthWali5ISK6egw35HS83F2gajT1O0zr0ex5Wg83/HlmImIC2zd1O9hHjY/mD8f1fYIAiNsz5FpnSkX6eSApyhcJwd6orDPhtpV7sHLbhTavecFauRkYIc7AupLxOh1hNFnwp++PY/3J/LZPJiLqoRhuyOkoFAp5xhRguyN4Z1y78YrFUrdUpJ8H3FyU+H7BaMwcFAaTRcBf15/F7vSSVq8nVW6mJoobv14oqurSVY53p5fgq4M5+MuaU1xNmYicFsMNOSWpa8rX0w0e7i6deu3k6IZp4XK3lJ9YHdJ6uuG9u4bilqRwAMD2c8UtXkcQBFywdkNN7BcMV6UC1UazvJN5YxaLgD0XSq56805po9CSKgPO5Le9KzoRUU/EcENOSVrIrzOrNpKBEVq4uyhRUmWUN9OM9POUX1coFJjYT+y62tfK4OKSKiP0dSYoFEBCsDeiA8RrNNc19cvJfNz17/149eczV9X28pqGXdB3nm85eBER9WQMN+SUAq3dUi1NA78aajcXDIrUAgDq6sVF9yJ8bcf1pMSJM6dO5uqgb6HactEaYqL8PKF2c0F8kDeA5gcVH8oU19dpaWfy9pIWNgTEae1ERM6I4YackrSQX0vTwK+W1DUFAK5KRZMZWaFaNWIDvWARgAMXy5q9hjTtOy5IHNCcEOxtPd403JwtELeSyCythsXS8bEyFTUN4eZgRjlqjeYOX4uIyFEx3JBTmjUkAqNi/XHH8KguuX7jcBPu69FkM00AuC5OHHjc0ro3UuVGqthI4ebyyo0gCPL4mLp6C/J0teioxt1SRrMF+zJKkVNWg9VHL6Gi0WtERD0ZN84kpzQwQouvH07psusP69UQbi7vkpKkxAfgywPZLa5YnFYoBhapctPbupDgmfxKWCwClNbAVKCvs+lOulhcbTPG50pI1/FRu6KyzoQPtl/AqTw9KutMcHdVYvrAUDw3rR/CW7gnIqKegJUbog4I8lEhxjoAONKv+SBwXZy4HcOZAn2Tqoi+rl4ebDzKum1DvzAfeLm7QFdbj7ONtng4e9mspotXsRaO1C01bYA49XzfxTJU1pmg9XCD0WTB2tQ8vLslvcPXJyJyBAw3RB0kdTtJ3UmXC/ZRIyHYG4IghojGNp8pRL1ZQO9gb3nrBzcXJYbHWPenatSVdcY63kZyNVs0SN1SMwaHwc1FrAzNGRaBA3+ehJdmDQAAnC/kFHEi6tkYbog66Llp/bDk5kT8PiW6xXPGWBf8+/fOi6g3W+Tj604UAACmDwqzOV/awqFxV5Y03kbqvpIW/lv8w3FMenNbi7OxmqOzVm6i/T3x/u+S8fZvhuDNO5KgcnWRu9oulnB/KyLq2RhuiDrIz8sd946Jhad7y0PX7h8bBx+1Kw5nleP1dWcBAFUGE7ZZF/ebPjDU5vwUazXoQEapvFv42XyxcnOTNQhdLK5GaZUBXx3MwYXiahzKbDobq7KuHjVGk82xerMFlQbxmK+nOyb1D8HsoRHyDuhSeCqrNnJwMRH1aAw3RF2oV4An/nZHEgDgo10Z+PpgNraeLYLRZEFsoBf6hdruRj4gXANvlSv0dSacydejrt4sV1JmDBbDTb6uDr+cyIe0e8LFy7qpaowmTHlrB25+d5cckADbNW60Hm5N2urp7ipPnb+866u40oD/HcuDqVH1iYjIUTHcEHWxqQNC8fD4OADAc9+fwDPfHQMgVm2kqonE1UWJkdYBxnsvlCK9qApmiwBfTzf0DfGBv3Vxwg93ZcjvybisG2nfxVLk6+pwobhaXh8HaBhMrFG7Njt1HWio3ly+1s5T36TiD18elatP7cUqEBHZA8MNUTd4ZmpfLJqYALWbUl7VePrAsGbPlbqm9l0slWdN9Q/VQKFQIM66g3lWaY18/uXhZse5hs06D2eVy7/W1Yohw9fTHS2JCxQHRzeuBp0t0GPnefGaH+3OwMFmusGaU20QK0i3vLfbZrwREVFXY7gh6gauLkr8cWpf7HhmIh4eH4c/TumDgRGaZs+VZmHtvlCCd7ecByBOEwcaFvwDAKn4cnm4abxnlLRtAwCUV4uVGz/Ppl1SEnnQcqPKzSe7MgEA7q5KCALwx2+PNRnP05xTeXqUVBmQXVZjE7IuV1xpQJG+6WahREQdxXBD1I2CNWosntEfi27o3aRLSpIYrkGgtzvq6i1yhWakdYq4FD6AhspPvq5ODhu5FbU242Uah4oK65gbbSuVGyk8SeN8SqsMWJ2aCwD44PfJCNOqkVVag79vONfmvZ7Jb+gS23K2qNlzDCYzZv5jJya9uR1ZpZylRUSdg+GGyMG4KBX47IFReGX2QLzz2yH4dkEKpllnVcU1qtzcnhwpV2EyS8QQtMtatekX6gMXpQK5FbXIqxC3a5DGvvg2M5hYIoWnrNJqmMwWfLE/G0aTBUmRWkzoE4TX5gwCAPxnbxZyympavA4Am/E+m88UNnvO0ewKFFUaUGkw4elvjtkMgG5LlcF0VftsEZHzYrghckD9QjX43XXRmDUkAiNi/OUqT79QHygUgLfKFSnxAYixjsGRuqaksTFTBoSiv7Ur65C1eiPNlmqtWypc6wG1mxL1ZgEXiqvxn31ZAID7xsZCoVBgYt9gjEkIgNFswVsbW6/enG60svKF4mpkllRDEATkVtRCsE712tNoPZ9DWeX4cOfFdv3+7LlQgkFLf8UHO9p3PhFdWxhuiHqQKOvie5/eNwJqNxfEyuFGnFW1K10MN+N7B2J4tNiVddg6AFhanbi1bimlUoGYAPGar/5yBsWVBkT4etgMfn5uWj8AwOrUXJuup8bMFgFp1sqNtD3F5rNF+Muakxjz+hb8Z68YmvZeENsrbVXx5oZz7eqeWneiAILQckWIiK5tDDdEPczUAaFItgYXafbUxZJqnMzVoaKmHt4qVyRF+WJ4jLjisFS5kaaCt9YtBTSMu9lhXWjw0YnxcHdt+KdicKQvZg4OgyAAT39zDFvTipp0D2WWVqOu3gK1mxLzU2IAAG9vPIfP92cDENf8qTKYcDS7AgDw19sGY3i0H4xmC7alFaMtxy6J7ztfVCVXgYiIJAw3RD1YrHXqdkZJNb4+lAMAGN8nUNynyhqAzuTrUWUwNXRLebUebhoPWg7XqnFHclSTc/44pS883V1wOl+Pez85iBn/2Gmzno1U0ekbqsGNiSEAIK+O7KpUILusBu9uPg+TRUCErwd6+XvKW0+cytO12j6DySxfX1dbj5IqrqNDRLYYboh6MKlb6nxhFX44cgkAMM9aKQnVqhHh6wGLABzNLpe7pXw9Wu6WAmzDzSMTE2yqNo0/95c/jMN9Y2Lho3bF2YJK/GNzw27iUvhIDPNBTKAX+oSIIezh8XH47UgxLP3bOr5mdHwAFAoFBoRrAYhTyFtzJr8S9eaGak16Ucd3SSci58RwQ9SDxQR6AhBnDtXVWzAwQoNR1hWOASA5WuyaSs2ukLultK0MKAbEbieFAojw9cCdwyNb+WwvvHBzIv559zAAwH/3ZcrjZaTNPvuFimv5rPxdMlbcNQzPTeuHuSN7AQCknqzRCWLFZkC4eO65wkoYTS0v+nfc2iUlSS/iLuZEZIvhhqgHa7wfFADcb53VJBnayxcAcDSnQt4R3K+VAcWAOObm+0dG47tHUqBydWmzDeN6B2F8nyDUmwUsX58GoGGzz/5hGvmaMweHQakUKzRJkVr5/SlxgQDEgcdaDzfUmwWcK2w5sKTmVAAA3F3Ef76kys2iL45g3PItKK9mNxXRtY7hhqiHk7qmgn1UmDko3Oa1ob3Eys3hrPKGHcHbGFAMAMN6+SFM69HuNiye3g8KBfDziXy8uSENeTpxxWFpZeXLSdWb+CAvhFrDmdg1JYah1sbdHL8kvjY5MRgAkF5chaLKOvx0PB85ZbXYcLqg3e1uTkWNEScutT7uh4gcG8MNUQ8ndT09OC6uyfiYxDAN3F2V8mBihQLQtCPcXKn+YRo5sLy7RRx7E+nnAY26+c+6PTkS/zejH968c4jN8YZw0/y4m8q6enlTzzlDxS6z84VV2N5ohtXmM82vhtxez31/HDe/t4vTzIl6MIYboh5u4cQErFk4Bg+Mi23ymrurEgPDG/aw0qjdWtwR/Gq9dMsALL9tsLxn1qR+wS2e6+qixEPj4zEkytfm+MAIsbvqZK4OgiBgw6kCmzE1J3J1EARxPNBI69o4RZUG/O9YnnzOrvQS1NWbO3wfR6zT07lAIFHP5WrvBhDR1VG7uTQJCY0N7eUn/8D2bWMw8dVwdVHizhFRuGN4JIoqDfD3an1sT3Okys2Z/Ep8vj8bf1lzEqEaNXY8OxHurkocyxG7i5KitNCo3RCqUaNAXyevzOzmokCN0Yz9GWW4vk9Qi59jMltwtqAS/cM0NmGvsq4exZUGAMCBjDKczNXJgYuIeg5Wboic3DDruBugfeNtrpZCoUCIRg03lyv/5yU20Bsebi6orTdj6f9OAQAK9HVYm5oLQRCwNU3schoc6QsASAhu2GvLz9NN7qraYu1S0tXUN7v/1L92XsRN7+7CF/uzbI5Le3RJPtmdiRqjCZ/uyZQHMjdmtgg4mFmGKkPbu6QTUfdhuCFyctKMKQDwbWOmlL25KBXynlgmiwBvlVhc/vfOi1h3sgAHMsrg7qrEzEHidhCNw8243kHygoGbzhThpR9PI+mlDXjhfyebfM5xawUoNcd24HCGdSp7gLXq9OOxPNz49x1Y8r9T+OO3x5pcZ/XRXNzx/l5M+ft2bD/X9srKRNQ9GG6InFyYVo0QjQpA13ZLdRZpMT8flSu+XZACL3cXnCuswjPWcPHw+DhE+Yvr+zQONxP6BmFMQiBUrkrkVtTi490ZAICvDuSgwDp7S5Jt3dH88n2sMorF55P6B2NIlC+MZgtyrbuqZ5RUo95su/7OgQxx4888XR3mf3wA724+f/W/AUR01RhuiJycQqHA0Cixa6o7uqWu1m9GRCEpUou3fzvEZhZWtdGMcK0aj05IkM9tHG7G9wmCh7sLxiSI6+b4qF0RF+gFk0XA5426nwRBQI413GSW2nZDZZSIM7FiA72xeHo/xAV54eHxcfBwc4HZ0vA+iTSra7h1xtr72y9wrysiB8BwQ3QNuHVYBLQebhjfyiBbRzEwQou1i8ZiUn+xi+nesbHyoN8/z0yEh3vDwoJDe/libEIg7hkdg0BvsTq1eHo/PDguFj8/Ng5/nNoXAPDlgWwYTOIMqoqaennNn5Iqg814mYwSsXITG+iFUXEB2PL0BCye0R8x8u7rDZUeo8kiLzb419sHQ6EQA1gZFxEksjvOliK6BkwdEIopiSE2qxf3FBG+Hlhx11AUVxowY1CozWsqVxd89sAom2O9Q3zw55mJAIBwXzXCtGrk6+rw8/F8zBkWKXdJSbJLa5AYroEgCLhoDS+N99cCxN3Xz+TrbcLN+SJxjyuthxviAr0Q4iPO3Mouq0GANWgRkX2wckN0jeiJwUYybWAYfp8Sc8X34OqixO+uiwYArNqTCQBNwo007qa02ojKOhMUCqCXdUyPRNrDq3G4kbqkEsM0UCgU8ntyymuvqI1E1PkYbojIqf12hLgL+fFLOpRWGZqEG2ncjRRcInw9oHaz3VMrNtDbem6jcJMrzrSS1uaRBjlfPi6HiLofww0RObUAbxXird1Mxy5VyOFDZd2qQqrcSDOlpL26GouVKjfFTSs3AyKkcCPuxZVd2rnhpq7ejM1nClFj5Fo6RO3FcENETi/JuoJzao5OrtyMjBW3b5CqMfJ4m2bDjVi5ydPVoa7eDItFwBnrzufS1PWGbqnODTf/3ZuF+z89hH9xOwiidmO4ISKnN1QONxVyuBnfW5w5li13S0nTwJuGGz9PN2jU4vyLzNJqZJZWo9pohspVKYchqVvq8m6v5tQYTe3uvkqzzsi6WFzdxplEJGG4ISKnJ1dussuRZ12Ub1wfcT0cqRojjbmJaSbcKBQKxAZZx92UVMtdUv3CNHC1bjMhVW7ydXVNFvtrrMZowuwVuzHxb9tsBii3JF8ntrekytDmuUQkYrghIqfXL1QDd1cl9HUmWARxvE3fEB/4WLd3OF9YJQ8sjgv0bvYasQFieLnYKNwMaLTjepC3CipXJcwWAfkVdc1eAwBe+vE0zhVWwWQRsDu9xOa1unoz/m/1CSz75Yx8LM96rasNNxkl1Zj05jZ8cyjnqq5D1BMw3BCR03N3VdoEkV7+nlAoFIi2DhRe+uMpGE0WhGvViPDzaPYa0rib03l6/HIiHwAwqNGO4UqlApHW97Y07uaXE/n46mBDuDjWaDPOGqMJ9396EF/sz8YHOy6ipMoAQRDkSlNJ1dUtDvj1wRxcKK7GF/uzr+o6RD0Bww0RXROSrDuJAw1dSNEBYhfU4axyAMBz0/vJqyFfTlrr5qfj+cguq0GYVo2bBofZnNOrlXE3p/P0+NP3xwEAQ6zdZMcuVQAQKzb3fHwQu9NL5fOzSmtQXlMPg0ns4iqvMcLUSndXvq4Wy9adwYhXN+G57443eV3aByu9qIpbRJDTY7ghomuCFCiAhsG/MQENi/UN7eWLW5LCW3z/5d1Vy+YMgo/adq+ulgYVnyusxO8+2g99nQnJ0X74593DAADni6pQZTBhbWouDmSWwUft2iggVctVGwAQBLS4tcPa1FyMX74VH2y/iOJKA1an5sJiaQgwNUYTjl8S1+WpMpiQp2u524zIGdg13OzYsQM333wzwsPDoVAosGbNmlbP37ZtGxQKRZNHQUFB9zSYiHqsxuFGrtz4NwwefuGmxFZXQJYqNwBwR3IkJvQNbnJOr2YW8surqMVd/96PsmojBkVo8fE9IxDu64EwrRqCAJzM1eHXU4UAgIfGxWF0fAAAILOkxibcAEBxM+Nutp8rxtPfHEO9WcDIGH+4KhUwmiwo0DcEmCNZFTA1CjvSnlhEzsqu4aa6uhpJSUlYsWLFFb0vLS0N+fn58iM4uOk/MkREjUUHeEJr3RVdqrCM7xOECF8PPHx9HIb28mv1/T5qN8wcHIbBkVr85abEZs+J9Gsabv6zNwslVQb0DfHBf+8fKbdB6ibbk16CXefFgcVTB4aiV0BD9Sf/sgpLcaVtuDlxSYdHPjsMk0XArCHh+Oqh6+RxP1mNFhPcn1Fq877zDDfk5Oy6ceb06dMxffr0K35fcHAwfH19O79BROS0FAoF/jilD3acL8G43uI08FCtGrv/dEO7r7HirmGtvn75/lIWi4D/peYCAB6f3Bu+nu7yuUlRvlh/qgCr9mTCaLYgNtALvYO9kV4krreTWVqNYI3tBpyXDype/utZ1BjNGJsQiDduT4JSqUCvAC9kltYgu6waKdYq0P6LZQDErSVyK2pxrrCq3fdM1BP1yDE3Q4YMQVhYGG688Ubs3r271XMNBgP0er3Ng4iuTb9PicG/5w1vsndUZ5G2YCirNqKyrh4HMsuQp6uDj8oVN/SzrTAnRYozrfR14rYKUwaIu7ZHS5Wb0pomU8obTwc3mS3yQOi/3NQf7tbtJKKtAUuq3NTVm5FqnZV193W9ALByQ86vR4WbsLAwvP/++/j+++/x/fffIyoqChMmTMCRI0dafM+yZcug1WrlR1RUVDe2mIiuJT5qNwR6i9WW1UdzsdZatZk+KLRJoBoYqUXjIT5TEkMBNMzgKq02ymNjInzF0FTSqFvqbEElaoxm+Khc0SfYRz4uhaMsa9fY0ewKGM0WBPuoMCUxBIA4kLnxgGMiZ9Ojwk3fvn3x8MMPIzk5GaNHj8bHH3+M0aNH46233mrxPYsXL4ZOp5MfOTlcwIqIus4jE+IBAK/8fAY/HhPXw5k9NKLJeRq1m7x1Q7CPSt4iwlvlikBvsfvqbIEYbgZbqzyNKzdHssWqzdBoPygbTV+XZ1tZKzfSeJtRcQGIDvCCm4sCNUYzci8brEzkTHpUuGnOyJEjkZ6e3uLrKpUKGo3G5kFE1FXuGxODG/oFw2iyoMpgQqhGjetiA5o9VxrEfGNiSLMBRTJIDjcNY26kLqnkywZCS5UfabdzabzNqFh/uLko5Snt54uurmvKbBHwp++P46mvU7luDjmcHh9uUlNTERYW1vaJRETdQKFQ4I3bByPEOhj4liHhNsGlsccn9caD42Lx1I19bI7HBDRMUXdRKtA/TPyfssaVGzncRNuGGykY6etMKNLXyRWe6+LEXdB7h4jhprVBxccvVWDmP3bipnd3Yu+F0mbPeW9LOr46mIMfjua2a7NQou5k19lSVVVVNlWXjIwMpKamwt/fH7169cLixYuRm5uL//znPwCAt99+G7GxsRgwYADq6urw4YcfYsuWLdiwYYO9boGIqIkAbxVW3TsS3xzKwaPWbqrmRPl74s8zm04r79VoccEQHxVCfNQAGsJNob4Ol8proVAASVFam/d6uLsgRKNCod6A/x3Lg8FkQYCXO+KtG3/2CfEBkN/sWjdmi4B3t5zHu1vSYbaOyZn7732YMywCf7POxgKA/RdL8c7mc/L7LpXXyhUjIkdg13Bz6NAhTJw4UX7+1FNPAQDmz5+PVatWIT8/H9nZDfugGI1GPP3008jNzYWnpycGDx6MTZs22VyDiMgR9A/TYMnNAzr03saVmzBfDwT5iFWg0mpxC4Yj1qpN3xCfJqskA+LihIV6A749dAkAMDLWX16gsI+1cnP+ssqN0WTBk1+n4mfrvlkzB4fBz9MNn+/Pxg9HcnFzUjgm9g1GZV09Hv8qFY3HI19qYS8tInuxa7iZMGFCq321q1atsnn+7LPP4tlnn+3iVhER2Vfjyk2YVg1/L3coFYBFAMpqjC12STV+/4HMMqRZqzOjYv3l1/qGil1caQWVKKs2wt/LHTVGEx7+72HsPF8CNxcFXp8zGLclRwIASquMWHeyAJkl1UBfYN/FMhTo6xCuVeO6+AD8cCQXOWUcnEyOpcePuSEicjaNKzfhvh5wUSrg7yXOoCqpNOJwduvhJvqyAcmj4hoGNMcEeGJwpBZGswX/2ZsJAPjLmpPYeb4EHm4u+Gj+CDnYAA3T0HOtCxNKVZohvXzRN8TH5hiRo2C4ISJyMH6ebvBRi4X1cK043kZaP+dCcRVO5oqbYLZWuZH4errJIQQQBzw/ND4OgLg1xM7zxfjhSC4UCuDje0ZgfJ8gm2tFWLdzkKaOS1WaSD/Phu0mylm5IcfCcENE5GAUCgUSgsWxMdJAXSncfLonE/VmAf1CfVocxNu48jMixr/JbK1pA0IR6eeBsmojHvzPIQDAb4ZHyds1NCZXbipsKzdRfh7yPlas3JCjYbghInJAL88aiP+b0U/eB0ta2O+QdbzNnGFNFwaURDeq3DQebyNxdVHigbGxAIC6egu0Hm54dlq/Zq8lV26s1RmpShPp5ylvQFqoN6Cu3tz+myPqYgw3REQOaGCEFg+Nj4eri/jPtFS5AQClApg1pOVw4+vpjmDrDKsxCYHNnnPniCj4eoozrZ6Z2lce03O5SF8xwJRWG1FrNDdUbvw94OfpBk93cVuJvHaueFxrNOOf29KbnYpO1FnsOluKiIjaJ9CnIdyM7R2EEI261fNX/m4YCnQGeQHAy3m6u+Kj+SNwtkCPuSN6tXgdjYcrvFWuqDKYcKZAj0rrRp8Rvp5QKBSI8vNEWmElLpXXIs66lk5rvjucg+Xr07By6wWsum8EkqObVpaIrhYrN0REPUDjys1trXRJSZKj/TFzcOurtydH++HuUdEtrqAMiON/pHE3+y6Wym3xsFZspHE3OY3G3VgsAt7ZdB6/nipocr3UHHEwdKXBhN9/dKDFFZCJrgbDDRFRDyBt5+Dl7iLvIN5dpHE3+6z7VEmBpvGvLzWaMbX9XDHe2nQOT36d2mQsjjTTK8LXAzVGMx778oi8GjJRZ2G4ISLqAa6LC8DckVF4bc4guWrSXaTKzaFMMdxENVpHR/p1TqP9pTacFis2NUYztqUVy8drjWZ5w84vHhwFH7UrSqqMOH6pokvbT9cehhsioh7AzUWJZXMGtzqQuKtIlZsao1iFaa1yY7EI2HSmSH79F+t2DgBwpkAPiyDO/Orl74nR1qnnu86XtLstJVUG/O3XNJtNRIkux3BDREStkio3kii/hsqNtJCfFG5SL1WguNIAaRjP5jOFctfUKWuX1MAILRQKBcb2FhcM3Jne/nDz3pZ0vLc1HW9uSOvYzVhVG0x4b8t5XCxueXd06rkYboiIqFURfrbhpnHlRgo6JVUG1BrN2Hi6EAAwfVAYwrVqVBvN2H5O7Jo6masHAAwMF3cyH2edpn40uxzVBlO72nLUuvXEtrTiVvcmbMsPRy7hbxvO4c0N59o+mXochhsiImpV5OWVm0ZjbjQervBRiauK5FbUyOFmSmIIpg8SZ2tJXVMn5MqNOD09OsATkX4eqDcL2J/R9qwpg8mM0/liQMrX1eF8kW3VRRAEHMupwN83pOGBTw8iNaeixWuds+6KfrGkus3PpZ6H4YaIiFoV6K2Cu6v440KhAMJ9G9bYUSgUiLSGnf/74STSi6rgqlRgQt9gzLCGm81nilBaZZAX7hsYoZXfO07qmmrHuJuz+ZWoNzdUa7Y3GqycXVqDOz/Yi1krduMfW9Kx6UwR3ttyvsVrZVhDDbeOcE4MN0RE1CqlsmGtmxAfNVSutrO1xlgHBh+wzqYaFecPrYcbhkb5IjrAE1UGE+7+cD9MFgG+nm42Y3ik7SXaM6hYmlWlsI7nkbq71hzNxfR3duBgZjk83FzkgcoHM8thaWGauTTWprLOBF1NfZufTT0Lww0REbVJCiSRl42/AYA/z+yP/y0ag6dv7IPpA0Px7FRxnyqlUoF3fjsU7q5KnC0QqzaDrIOJJaPjA6BQAOeLqlCor2u1Dccuid1aUkXoQEYZ1p3Ix5PfpKLaaMaIGD9seHI8Pr1vJDzcXKCrrZe7rurqzagxiuN6ao1m5OkaPiuH1Runw3BDRERtksJN4/E2EoVCgcGRvnhsUm+s/F0ykqJ85deGRPni9TmD5OcDrIOJJb6e7ugfKo7BaW2MDAAcs74+e0gEovw9YDRbsOjLoxAE4M7hkfjqoRRE+XvCzUWJYdFiGw5klsFiEXDH+3sxfvlW6GrqkVlqO86GXVPOh+GGiIjalGLt6kmJC7ji984ZFoknJveGn6cbZg5quiVEYrgYbs5YBws3p8pgQrq1KykpSovr+4hjdcwWAYMitHhp1kC4NNpGYmSMtassowy7L5TgRK4OJVVG7MsolcfbSBqvrkzOgRtnEhFRm2YPjcDkxBB4qzr2Y+OJyX3w+KTeNl1SkkTr5p6n81oONydzdRAEIEyrRrCPGpP6heCzfdnQerjhn3cPg9rNdhzQiFg/AMDBjDKbKeOHMsug9XCzObfx6srkHFi5ISKidulosJE0F2wAyDuXS9O8K2qMWPDfw1ibmiufIw0mTor0BQBM6BuEN+9IwrcLUprtKhsa5Qc3FwUK9HVYd7JhA89DWeXy9O9wrTjri5Ub58NwQ0REdiVVbi6V10JXW49vD13C+lMFeOLrVKw/WQCzRcCudHEdnMFRDdPIb0uORJ8Qn2av6eHugkHWKedmi4BQjRhkTubqcCZfHNw83tq1xQHFzofhhoiI7ErbaHr42Xw9tp0T96YSBODxr47i1n/uxg7rtO/R8YHtvu6IWH/5149MiEewjwr1ZkEe2yOFm0vltRAEAY9+fhgjXt2E4kruW9XTMdwQEZHdSV1Th7LKcTBD3GJhSJQvDCYLjl/SwVvlijduH4whjWZitWWUNdy4uyoxe0gEhsf42bw+Jj4QCoW4IejpfD1+OVGA4koDfj6e1zk3RXbDcENERHaXGCZ2L/13bxaMZgui/D3wxYOjMGNQKGYMCsWvT47HHcOjruia43sHYV5KNF6ZPRBaTzcMj26o5IRr1dB6uiHER+yu+mR3pvza+lMFl1+KehjOliIiIruTpoMXWBfym9AnGJ7urvjn3ckdvqarixIvzRooP29cuYkN8gIgLkpYoK/D/1IbqjUHMspQWmVAgLeqw59N9sXKDRER2V1imO3iftI6Np37GRp4uotTxuMCvQE0LEpoNFsAAME+KlgEYNOZwk7/fOo+DDdERGR3kX4e8lRzdxelvGhgZ3J1UWJYL7F6kxDsLX+uJC7QC/NSogEA60/adk2dztNj69kiFOjqbNbNIcfEcENERHanVCrQ3zruZkSsH7yuck2dljx/UyIevj4OdwyPBABE+TWskXPjgBBMGxgKANidXgp9XT3MFgHL15/FjH/sxL2rDuK6ZZsx/Z2dbe6D1ZYfjlzC9Hd2IvOy1ZKpczDcEBGRQxibIHZF3ZIU3mWf0TfUB4un94enuxieIv0bKjdTEkOQEOyD+CAvGM0W3PLuLtz87i78c9sFAEBsoBeUCuBsQSXe2XweAJBeVIkxr2/Bsl/OXFE7PtmdiTP5enZ/dRGGGyIicgiPTozH+ifG4c4rnBV1NfqG+MDT3QUxAZ4YEiV2Wf3+OrFrKrO0Bqfz9fBwc8E7vx2CrX+cgK8eSgEAfHMwB9mlNXju+xPIrajFR7sy2r0+Tq3RLK+1U6C7ugoQNY+zpYiIyCG4uSjRz7pDeHcJ8Fbhlz+Mg6fKRd54854xsZgxKAyn8/XIKavB2N5BiA0UZ1eNjPXHmIQA7E4vxd0f7UNOmbh1g8ki4NvDOXh0QkKbn3kyTweTRRy3k89w0yVYuSEiomtaTKAXgq3r3UiCNWpM6BuM36fEyMFG8uTkPgAgB5vr4sT1c746kAOLpe3BxqnZFfKv83Tc16orMNwQERFdgeEx/hjXW9wGYlgvX3w0fwR81K7ILqvBrvQSHMwsw/eHL8mzqswWAW9uSMMG6+KAR3PK5WuxW6prsFuKiIjoCi2bMwirdmfivrGx8FK5Ys7QCHy6NwsLPz+CSoMJAODqosCsIRHYfKYQ725Jh6e7C/YunoSjjSo3hfo6mMwWuLqw1tCZ+LtJRER0hSL9PPGXmxIRbt3w865R4iBkKdgAwIZT4kyorWniRqA1RjP+sfk88nV1UCoAV6UCFgEo4kadnY7hhoiI6Cr1DfXB0pvFNXT+efcwAMD2c8UwmMzYerZYPu/j3RkAgD4hPgjRiON8OKi487FbioiIqBPcMyYWAGCxCAj0VqGkyoD/7MlCgb4OHm4uULspUV5TDwAY2ssP6UWVyK2oRb6uFoBfK1e+MvsvlkIAcF1c56/y3FOwckNERNSJlEoFbugnLkj49qZzAIAxCYG429p1BQBDe/kiTCt2aeVX1KGu3ozf/msvnvw6FXX1ZpvrpRVU4rrXNuO9Lefb/OySKgN+/9EBzPv4AHS19Z11Sz0Oww0REVEnu6FfCACg2mi2Pg/G71Oi4WpdSyc52g9h2oZuqYOZZdh3sQyrj+bivlUHUd1o7M4/Np9Hgb4Ob206j/SiylY/d8OpQhjNFhhNFpzK03XFrfUIDDdERESdbFzvQLg3mgE1sV8QQjRqfPD7ZCy/fTDig7wbhZtaHMmqkM/dc6EU8z4+gFqjGTllNVh3Mh+AOKX8lZ9b3+ZBOhcATuXqO/GOehaOuSEiIupkXipXpMQHYPu5YvQP08hdUJP6h8jnhFlnWuXp6lBjrfDcnhyJDacKcDirHP+3+gQCvNxhEYD+YRqkF1ViW1ox3ttyHucKq2A0WfD33yTJ+2SVVxux50KpfP0TuazcEBERUSe6a1Qv8b8jm98rS6rc5FXU4mi2uLDfvJRofPD74XBRKrD6aC4+2ZMJAHhmah/cMzoGAPC3Defwv2N5WH+qAJvOFMnX23imEGaLADcXsevrJLuliIiIqDNNHRCKMy9Nw++ui272damaU1xpgL7OBLWbEv3DNEiJD8Di6f0AiF1RcUFemNAnGItu6I24IC8E+ajQO9gbAHAkq2G143UnxC6pu0aKoSqjpBpVjcbuXEsYboiIiLqIh7sLFApFs68FeLnbjMsZHOELN+vz+8fGYvaQcADAookJUCoV0Hq4YcvTE3Dwz5Ox6AZxg06p4qOvq8eu9BIAwO9TohGmVUMQIO8+fq1huCEiIrIDpVKBEK1Kfj402lf+tUKhwFu/GYKdz07EnGGRTd47rJe4Ls6pPD3q6s3YfKYQ9WYBCcHeSAj2wYBwLQDgZAvjbvakl+Dn4/nNvuYMGG6IiIjsROqaAoChUbYL+SkUCkT5ezb7vkg/DwR6q2CyCDiRq8MvJ8RNOWcMDAUADIzQAABONjNjqtZoxv2fHsLCL45gy9nCTrkPR8NwQ0REZCfh1kHFADCsUeWmLQqFAsN6iefvPF+C7efELR6mDwoDAAy0Vm6aW+tmf0Ypaq0LBb6w9hRqjeYm53RUvq4Wj315FJ/vz+q0a3YEww0REZGdhForN5F+Hgj2Ubdxtq1h0WKl55NdGTCaLIgJ8ES/UB8AwMAIMdycL6pqsuLxrvMl8q8vldfiva2tr3y86XQhZr23C6fz2h6/czCzHD8ey8PXB3Ou6F46G8MNERGRnfQJEWc9pXRgH6ihUb4AGnYinz4oTB68HKJRIdDbHWaLgNOXDSqWBh7fnCQOWP7Xjoutrny8ak8mjl3SYcn/TkIQhFbbdDizDEDDmCB7YbghIiKyk5uTwvHhvOH4y8zEK37v4EhfeTsHAJgxMEz+tUKhQLK1srP2aK58vKiyDmcLxCCz9OZE3NAvGPVmAX9Z03xwEQRB7to6mFmObeeKm5zT2GHr7C3ps+2F4YaIiMhO3FyUmJwYAq2n2xW/18PdBf3DxIHDkX4e8iBiibS+zreHL8mbaO62Vm0GhGsQ4K3Ci7cMgNpNiX0Xy7AmNReXy9PVyTuZA8Ab69PEalCeHoX6Optzqw0mnMkXg9PwGIYbIiIi6oDR8WJ31k2Dw5uspzM2IRC9g71RYzTj20PiGJid1vE2Y3sHAgCi/D3x2A29AQCv/nwGuhrbncRPWaeSR/l7wFvlitP5eox4dRNm/GMnpr+zE0WVDQHnWE4FzBYB4Vq1zSwwe7BruNmxYwduvvlmhIeLX8qaNWvafM+2bdswbNgwqFQqJCQkYNWqVV3eTiIiIkf02KTeeOs3SXhicu8mrykUCtw3NhaAOG7GZLbIlZvxvYPk8x4cF4f4IC+UVBnxf2tOwGJp6J46ZR1EPDImAA+ME69VVm2U/7tk7Sn53MPW1ZKTY/w78xY7xK7hprq6GklJSVixYkW7zs/IyMDMmTMxceJEpKam4oknnsADDzyAX3/9tYtbSkRE5Hi8Va64dWgk1G4uzb5+69AI+Hm64VJ5LYa+vBGFegNUrkqbMTHurkosmzMYrkoFfj6ej9d+adh5XAo3A8I1WDgxAS/PGoCP5g/H6kdHw1WpwLqTBfjFuu3DISncWKeo25NddwWfPn06pk+f3u7z33//fcTGxuLNN98EAPTv3x+7du3CW2+9halTp3ZVM4mIiHoktZsLfp8Sg39sPo/KOhNclArcMzqmSRgaGeuP5bcPxlPfHMOHuzIQqlXjgXFx8mDiAeEauLko8fuUGPk9j05MwD82n8fza05iUIQWR6yDiYc7QOXGruHmSu3duxeTJ0+2OTZ16lQ88cQTLb7HYDDAYDDIz/X6a3OfDSIiujY9dkMCBkdoEaxRoU+IT4tVnjnDIlFcacCydWexfH0aUuIDkK8Tx9QkhmuanL9oYgI2nCrA2YJKzFqxG5V1Jni4uchr7dhTjxpQXFBQgJCQEJtjISEh0Ov1qK2tbfY9y5Ytg1arlR9RUc1vPU9EROSMpBlZgyN9Www2kofGx2FkrD+MZgue/uYYACAmwBM+6qazudxdlfjk3hGIDfSSx+EMifKFq4v9o4X9W9DFFi9eDJ1OJz9ycuy7aiIREZGjUigUeHJyHwCQ18ORNuFsTpjWA18/dB3ig7wAACnxV74YYVfoUd1SoaGhKCy03eSrsLAQGo0GHh7NTztTqVRQqVTNvkZERES2UuIDcF2cP/ZdFFcbbq5LqrFgjRrfPzIaW84WYeqA0O5oYpt6VOUmJSUFmzdvtjm2ceNGpKSk2KlFREREzucJa/UGaNinqjW+nu6YMywSXirHqJnYNdxUVVUhNTUVqampAMSp3qmpqcjOzgYgdinNmzdPPn/BggW4ePEinn32WZw9exb//Oc/8c033+DJJ5+0R/OJiIic0nVxAZg7MgrJ0X4Y6QCzn66UXSPWoUOHMHHiRPn5U089BQCYP38+Vq1ahfz8fDnoAEBsbCx+/vlnPPnkk3jnnXcQGRmJDz/8kNPAiYiIOtmyOYPt3YQOUwhtbfHpZPR6PbRaLXQ6HTSa1vsRiYiIyDFcyc/vHjXmhoiIiKgtDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORWGGyIiInIqDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip+Jq7wZ0N2kTdL1eb+eWEBERUXtJP7eln+OtuebCTWVlJQAgKirKzi0hIiKiK1VZWQmtVtvqOQqhPRHIiVgsFuTl5cHHxwcKhaJTr63X6xEVFYWcnBxoNJpOvbYjcPb7A3iPzsDZ7w/gPToDZ78/oPPvURAEVFZWIjw8HEpl66NqrrnKjVKpRGRkZJd+hkajcdo/rIDz3x/Ae3QGzn5/AO/RGTj7/QGde49tVWwkHFBMREREToXhhoiIiJwKw00nUqlUWLJkCVQqlb2b0iWc/f4A3qMzcPb7A3iPzsDZ7w+w7z1ecwOKiYiIyLmxckNEREROheGGiIiInArDDRERETkVhhsiIiJyKgw3nWTFihWIiYmBWq3GqFGjcODAAXs3qcOWLVuGESNGwMfHB8HBwZg9ezbS0tJszpkwYQIUCoXNY8GCBXZq8ZVZunRpk7b369dPfr2urg4LFy5EQEAAvL29cdttt6GwsNCOLb5yMTExTe5RoVBg4cKFAHrm97djxw7cfPPNCA8Ph0KhwJo1a2xeFwQBL7zwAsLCwuDh4YHJkyfj/PnzNueUlZXh7rvvhkajga+vL+6//35UVVV14120rLX7q6+vx3PPPYdBgwbBy8sL4eHhmDdvHvLy8myu0dz3/vrrr3fznbSsre/wnnvuadL+adOm2ZzjyN8h0PY9Nvf3UqFQ4I033pDPceTvsT0/H9rzb2h2djZmzpwJT09PBAcH45lnnoHJZOq0djLcdIKvv/4aTz31FJYsWYIjR44gKSkJU6dORVFRkb2b1iHbt2/HwoULsW/fPmzcuBH19fWYMmUKqqurbc578MEHkZ+fLz+WL19upxZfuQEDBti0fdeuXfJrTz75JH788Ud8++232L59O/Ly8jBnzhw7tvbKHTx40Ob+Nm7cCAC444475HN62vdXXV2NpKQkrFixotnXly9fjn/84x94//33sX//fnh5eWHq1Kmoq6uTz7n77rtx6tQpbNy4ET/99BN27NiBhx56qLtuoVWt3V9NTQ2OHDmC559/HkeOHMEPP/yAtLQ03HLLLU3Ofemll2y+18cee6w7mt8ubX2HADBt2jSb9n/55Zc2rzvydwi0fY+N7y0/Px8ff/wxFAoFbrvtNpvzHPV7bM/Ph7b+DTWbzZg5cyaMRiP27NmDTz/9FKtWrcILL7zQeQ0V6KqNHDlSWLhwofzcbDYL4eHhwrJly+zYqs5TVFQkABC2b98uH7v++uuFxx9/3H6NugpLliwRkpKSmn2toqJCcHNzE7799lv52JkzZwQAwt69e7uphZ3v8ccfF+Lj4wWLxSIIQs/+/gRBEAAIq1evlp9bLBYhNDRUeOONN+RjFRUVgkqlEr788ktBEATh9OnTAgDh4MGD8jnr1q0TFAqFkJub221tb4/L7685Bw4cEAAIWVlZ8rHo6Gjhrbfe6trGdZLm7nH+/PnCrFmzWnxPT/oOBaF93+OsWbOEG264weZYT/oeL//50J5/Q3/55RdBqVQKBQUF8jkrV64UNBqNYDAYOqVdrNxcJaPRiMOHD2Py5MnyMaVSicmTJ2Pv3r12bFnn0el0AAB/f3+b459//jkCAwMxcOBALF68GDU1NfZoXoecP38e4eHhiIuLw913343s7GwAwOHDh1FfX2/zffbr1w+9evXqsd+n0WjEZ599hvvuu89ms9ie/P1dLiMjAwUFBTbfm1arxahRo+Tvbe/evfD19cXw4cPlcyZPngylUon9+/d3e5uvlk6ng0KhgK+vr83x119/HQEBARg6dCjeeOONTi31d4dt27YhODgYffv2xSOPPILS0lL5NWf7DgsLC/Hzzz/j/vvvb/JaT/keL//50J5/Q/fu3YtBgwYhJCREPmfq1KnQ6/U4depUp7Trmts4s7OVlJTAbDbbfEkAEBISgrNnz9qpVZ3HYrHgiSeewJgxYzBw4ED5+F133YXo6GiEh4fj+PHjeO6555CWloYffvjBjq1tn1GjRmHVqlXo27cv8vPz8eKLL2LcuHE4efIkCgoK4O7u3uQHRkhICAoKCuzT4Ku0Zs0aVFRU4J577pGP9eTvrznSd9Pc30PptYKCAgQHB9u87urqCn9//x733dbV1eG5557D3LlzbTYk/MMf/oBhw4bB398fe/bsweLFi5Gfn4+///3vdmxt+02bNg1z5sxBbGwsLly4gP/7v//D9OnTsXfvXri4uDjVdwgAn376KXx8fJp0e/eU77G5nw/t+Te0oKCg2b+r0mudgeGGWrVw4UKcPHnSZkwKAJs+7kGDBiEsLAyTJk3ChQsXEB8f393NvCLTp0+Xfz148GCMGjUK0dHR+Oabb+Dh4WHHlnWNjz76CNOnT0d4eLh8rCd/f9e6+vp63HnnnRAEAStXrrR57amnnpJ/PXjwYLi7u+Phhx/GsmXLesQy/7/97W/lXw8aNAiDBw9GfHw8tm3bhkmTJtmxZV3j448/xt133w21Wm1zvKd8jy39fHAE7Ja6SoGBgXBxcWkyErywsBChoaF2alXnWLRoEX766Sds3boVkZGRrZ47atQoAEB6enp3NK1T+fr6ok+fPkhPT0doaCiMRiMqKipszump32dWVhY2bdqEBx54oNXzevL3B0D+blr7exgaGtpkkL/JZEJZWVmP+W6lYJOVlYWNGzfaVG2aM2rUKJhMJmRmZnZPAztZXFwcAgMD5T+XzvAdSnbu3Im0tLQ2/24Cjvk9tvTzoT3/hoaGhjb7d1V6rTMw3Fwld3d3JCcnY/PmzfIxi8WCzZs3IyUlxY4t6zhBELBo0SKsXr0aW7ZsQWxsbJvvSU1NBQCEhYV1ces6X1VVFS5cuICwsDAkJyfDzc3N5vtMS0tDdnZ2j/w+P/nkEwQHB2PmzJmtnteTvz8AiI2NRWhoqM33ptfrsX//fvl7S0lJQUVFBQ4fPiyfs2XLFlgsFjncOTIp2Jw/fx6bNm1CQEBAm+9JTU2FUqls0pXTU1y6dAmlpaXyn8ue/h029tFHHyE5ORlJSUltnutI32NbPx/a829oSkoKTpw4YRNUpbCemJjYaQ2lq/TVV18JKpVKWLVqlXD69GnhoYceEnx9fW1GgvckjzzyiKDVaoVt27YJ+fn58qOmpkYQBEFIT08XXnrpJeHQoUNCRkaGsHbtWiEuLk4YP368nVvePk8//bSwbds2ISMjQ9i9e7cwefJkITAwUCgqKhIEQRAWLFgg9OrVS9iyZYtw6NAhISUlRUhJSbFzq6+c2WwWevXqJTz33HM2x3vq91dZWSkcPXpUOHr0qABA+Pvf/y4cPXpUni30+uuvC76+vsLatWuF48ePC7NmzRJiY2OF2tpa+RrTpk0Thg4dKuzfv1/YtWuX0Lt3b2Hu3Ln2uiUbrd2f0WgUbrnlFiEyMlJITU21+XspzS7Zs2eP8NZbbwmpqanChQsXhM8++0wICgoS5s2bZ+c7a9DaPVZWVgp//OMfhb179woZGRnCpk2bhGHDhgm9e/cW6urq5Gs48ncoCG3/ORUEQdDpdIKnp6ewcuXKJu939O+xrZ8PgtD2v6Emk0kYOHCgMGXKFCE1NVVYv369EBQUJCxevLjT2slw00neffddoVevXoK7u7swcuRIYd++ffZuUocBaPbxySefCIIgCNnZ2cL48eMFf39/QaVSCQkJCcIzzzwj6HQ6+za8nX7zm98IYWFhgru7uxARESH85je/EdLT0+XXa2trhUcffVTw8/MTPD09hVtvvVXIz8+3Y4s75tdffxUACGlpaTbHe+r3t3Xr1mb/XM6fP18QBHE6+PPPPy+EhIQIKpVKmDRpUpN7Ly0tFebOnSt4e3sLGo1GuPfee4XKyko73E1Trd1fRkZGi38vt27dKgiCIBw+fFgYNWqUoNVqBbVaLfTv31947bXXbIKBvbV2jzU1NcKUKVOEoKAgwc3NTYiOjhYefPDBJv+T6MjfoSC0/edUEAThgw8+EDw8PISKioom73f077Gtnw+C0L5/QzMzM4Xp06cLHh4eQmBgoPD0008L9fX1ndZOhbWxRERERE6BY26IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IqMe55557MHv2bHs3g4gcFMMNERERORWGGyJyWN999x0GDRoEDw8PBAQEYPLkyXjmmWfw6aefYu3atVAoFFAoFNi2bRsAICcnB3feeSd8fX3h7++PWbNmITMzU76eVPF58cUXERQUBI1GgwULFsBoNNrnBomoS7jauwFERM3Jz8/H3LlzsXz5ctx6662orKzEzp07MW/ePGRnZ0Ov1+OTTz4BAPj7+6O+vh5Tp05FSkoKdu7cCVdXV7zyyiuYNm0ajh8/Dnd3dwDA5s2boVarsW3bNmRmZuLee+9FQEAAXn31VXveLhF1IoYbInJI+fn5MJlMmDNnDqKjowEAgwYNAgB4eHjAYDAgNDRUPv+zzz6DxWLBhx9+CIVCAQD45JNP4Ovri23btmHKlCkAAHd3d3z88cfw9PTEgAED8NJLL+GZZ57Byy+/DKWSxWwiZ8C/yUTkkJKSkjBp0iQMGjQId9xxB/7973+jvLy8xfOPHTuG9PR0+Pj4wNvbG97e3vD390ddXR0uXLhgc11PT0/5eUpKCqqqqpCTk9Ol90NE3YeVGyJySC4uLti4cSP27NmDDRs24N1338Wf//xn7N+/v9nzq6qqkJycjM8//7zJa0FBQV3dXCJyIAw3ROSwFAoFxowZgzFjxuCFF15AdHQ0Vq9eDXd3d5jNZptzhw0bhq+//hrBwcHQaDQtXvPYsWOora2Fh4cHAGDfvn3w9vZGVFRUl94LEXUfdksRkUPav38/XnvtNRw6dAjZ2dn44YcfUFxcjP79+yMmJgbHjx9HWloaSkpKUF9fj7vvvhuBgYGYNWsWdu7ciYyMDGzbtg1/+MMfcOnSJfm6RqMR999/P06fPo1ffvkFS5YswaJFizjehsiJsHJDRA5Jo9Fgx44dePvtt6HX6xEdHY0333wT06dPx/Dhw7Ft2zYMHz4cVVVV2Lp1KyZMmIAdO3bgueeew5w5c1BZWYmIiAhMmjTJppIzadIk9O7dG+PHj4fBYMDcuXOxdOlS+90oEXU6hSAIgr0bQUTUHe655x5UVFRgzZo19m4KEXUh1mGJiIjIqTDcEBERkVNhtxQRERE5FVZuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORWGGyIiInIqDDdERETkVBhuiIiIyKn8P82t4phFtIkoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13) Inferencia greedy (generación en decoder)\n",
        "Generamos token a token con el decoder, usando máscara causal.\n",
        "Usamos greedy (argmax) para simplificar."
      ],
      "metadata": {
        "id": "6kvT9cknHEUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def greedy_decode(model, src_idx, max_new_tokens=20):\n",
        "    \"\"\"\n",
        "    Decodificación autoregresiva greedy para un Transformer encoder-decoder.\n",
        "\n",
        "    model: modelo entrenado\n",
        "    src_idx: (B, S) ids de entrada\n",
        "    max_new_tokens: límite de generación\n",
        "    devuelve:\n",
        "      ys: (B, T_gen) secuencia generada (incluye BOS y EOS)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    src_idx = src_idx.to(device)\n",
        "\n",
        "    # -------------------------\n",
        "    # Encoder (una sola vez)\n",
        "    # -------------------------\n",
        "    src = model.drop(model.pos_enc(model.tok_emb(src_idx)))\n",
        "    enc_out = model.encoder(src)   # (B, S, d_model)\n",
        "\n",
        "    # -------------------------\n",
        "    # Inicializamos el decoder con BOS\n",
        "    # -------------------------\n",
        "    B = src_idx.size(0)\n",
        "    ys = torch.full((B, 1), BOS, dtype=torch.long, device=device)\n",
        "\n",
        "    # -------------------------\n",
        "    # Decodificación autoregresiva\n",
        "    # -------------------------\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Embedding + pos enc del decoder\n",
        "        tgt = model.drop(model.pos_enc(model.tok_emb(ys)))\n",
        "\n",
        "        # Decoder con cross-attention al encoder\n",
        "        dec_out = model.decoder(tgt, enc_out)\n",
        "\n",
        "        # Logits del último timestep\n",
        "        logits = model.lm_head(dec_out)[:, -1, :]  # (B, vocab)\n",
        "\n",
        "        # Elección greedy del siguiente token\n",
        "        next_tok = logits.argmax(dim=-1, keepdim=True)  # (B,1)\n",
        "\n",
        "        # Añadimos el token generado\n",
        "        ys = torch.cat([ys, next_tok], dim=1)\n",
        "\n",
        "        # Si todas las secuencias generaron EOS, paramos\n",
        "        if (next_tok == EOS).all():\n",
        "            break\n",
        "\n",
        "    return ys\n",
        "\n",
        "# Probamos\n",
        "src, tgt_in, tgt_out = make_toy_batch(batch_size=3)\n",
        "pred = greedy_decode(model, src)\n",
        "print('src:', src)\n",
        "print('target_out:', tgt_out)\n",
        "print('pred:', pred.cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaSF9zxQHNa8",
        "outputId": "8aa94863-c8ea-4079-c74a-3cc52a9a129d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: tensor([[12,  9,  4,  7,  7,  7,  2,  0],\n",
            "        [ 3,  8, 10,  2,  0,  0,  0,  0],\n",
            "        [12, 10, 12, 11,  7,  6,  4,  2]])\n",
            "target_out: tensor([[22, 19, 14, 17, 17, 17,  2,  0],\n",
            "        [13, 18, 20,  2,  0,  0,  0,  0],\n",
            "        [22, 20, 22, 21, 17, 16, 14,  2]])\n",
            "pred: tensor([[ 1, 22, 17, 22, 17, 17, 17, 17,  2,  2],\n",
            "        [ 1, 13, 18, 20,  2,  2,  2,  2,  2,  2],\n",
            "        [ 1, 20, 22, 22, 22, 16, 22, 16, 22,  2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejercicio: hacer una tarea sencilla de traducción de inglés a español**"
      ],
      "metadata": {
        "id": "CoamuNc2HvgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 1) Vocab + encode/decode\n",
        "# -------------------------\n",
        "PAD, BOS, EOS, UNK = 0, 1, 2, 3\n",
        "\n",
        "@dataclass\n",
        "class Vocab:\n",
        "    stoi: Dict[str, int]\n",
        "    itos: List[str]\n",
        "    pad: str = \"<pad>\"\n",
        "    bos: str = \"<bos>\"\n",
        "    eos: str = \"<eos>\"\n",
        "    unk: str = \"<unk>\"\n",
        "\n",
        "    @property\n",
        "    def pad_id(self): return self.stoi[self.pad]\n",
        "    @property\n",
        "    def bos_id(self): return self.stoi[self.bos]\n",
        "    @property\n",
        "    def eos_id(self): return self.stoi[self.eos]\n",
        "    @property\n",
        "    def unk_id(self): return self.stoi[self.unk]\n",
        "\n",
        "def build_vocab_from_parallel(pairs: List[Tuple[str, str]], min_freq: int = 1) -> Vocab:\n",
        "    # Vocab compartido (porque MiniTransformer tiene un solo embedding tok_emb)\n",
        "    from collections import Counter\n",
        "    c = Counter()\n",
        "    for en, es in pairs:\n",
        "        c.update(en.lower().split())\n",
        "        c.update(es.lower().split())\n",
        "    specials = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"]  # ids 0..3\n",
        "    itos = specials + [w for w, f in c.items() if f >= min_freq and w not in specials]\n",
        "    stoi = {w: i for i, w in enumerate(itos)}\n",
        "    return Vocab(stoi=stoi, itos=itos)\n",
        "\n",
        "def encode_text(v: Vocab, text: str) -> List[int]:\n",
        "    toks = text.lower().split()\n",
        "    return [v.stoi.get(w, v.unk_id) for w in toks]\n",
        "\n",
        "def decode_ids(v: Vocab, ids: List[int]) -> str:\n",
        "    return \" \".join(v.itos[i] if 0 <= i < len(v.itos) else \"<oov>\" for i in ids)\n",
        "\n",
        "def pad_2d(seqs: List[List[int]], pad_id: int) -> torch.Tensor:\n",
        "    T = max(len(s) for s in seqs)\n",
        "    out = torch.full((len(seqs), T), pad_id, dtype=torch.long)\n",
        "    for i, s in enumerate(seqs):\n",
        "        out[i, :len(s)] = torch.tensor(s, dtype=torch.long)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "nXtv2jDlIc10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 2) Datos EN->ES (muy pequeños, para demo)\n",
        "#    (Puedes añadir más pares para mejorar)\n",
        "# -------------------------\n",
        "pairs = [\n",
        "    (\"i like pizza\",            \"me gusta la pizza\"),\n",
        "    (\"i like coffee\",           \"me gusta el cafe\"),\n",
        "    (\"good morning\",            \"buenos dias\"),\n",
        "    (\"good night\",              \"buenas noches\"),\n",
        "    (\"how are you\",             \"como estas\"),\n",
        "    (\"thank you\",               \"gracias\"),\n",
        "    (\"you are welcome\",         \"de nada\"),\n",
        "    (\"i love nlp\",              \"me encanta el nlp\"),\n",
        "    (\"the dog is tired\",        \"el perro esta cansado\"),\n",
        "    (\"the cat is on the sofa\",  \"el gato esta en el sofa\"),\n",
        "    (\"today is sunny\",          \"hoy hace sol\"),\n",
        "    (\"i am learning pytorch\",   \"estoy aprendiendo pytorch\"),\n",
        "    (\"where is the bank\",       \"donde esta el banco\"),\n",
        "    (\"the park is green\",       \"el parque es verde\"),\n",
        "    (\"i go to the beach\",       \"voy a la playa\"),\n",
        "    (\"see you tomorrow\",        \"hasta manana\"),\n",
        "]\n",
        "\n",
        "vocab = build_vocab_from_parallel(pairs)\n",
        "print(\"Vocab size:\", len(vocab.itos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg8WMKfaIiwr",
        "outputId": "53cfe4f5-8af5-4902-d550-3febac8bc5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 3) Dataset seq2seq con teacher forcing\n",
        "#    src_idx  = [en_tokens] + [EOS]\n",
        "#    tgt_in   = [BOS] + [es_tokens]\n",
        "#    tgt_out  = [es_tokens] + [EOS]\n",
        "# -------------------------\n",
        "class EnEsDataset(Dataset):\n",
        "    def __init__(self, pairs: List[Tuple[str, str]], vocab: Vocab):\n",
        "        self.pairs = pairs\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self): return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        en, es = self.pairs[i]\n",
        "        src = encode_text(self.vocab, en) + [self.vocab.eos_id]\n",
        "        tgt_tokens = encode_text(self.vocab, es)\n",
        "        tgt_in  = [self.vocab.bos_id] + tgt_tokens\n",
        "        tgt_out = tgt_tokens + [self.vocab.eos_id]\n",
        "        return src, tgt_in, tgt_out\n",
        "\n",
        "def collate_seq2seq(batch, pad_id: int):\n",
        "    srcs, tgt_ins, tgt_outs = zip(*batch)\n",
        "    src = pad_2d(list(srcs), pad_id)\n",
        "    tgt_in = pad_2d(list(tgt_ins), pad_id)\n",
        "    tgt_out = pad_2d(list(tgt_outs), pad_id)\n",
        "    return src, tgt_in, tgt_out\n",
        "\n",
        "dl = DataLoader(\n",
        "    EnEsDataset(pairs, vocab),\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda b: collate_seq2seq(b, vocab.pad_id)\n",
        ")"
      ],
      "metadata": {
        "id": "p4sy-9a0IlVV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}